import json
from typing import List, Dict, Any
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import pdb
from visual import compute_tree_plane_normals, calculate_perpendicular_plane, find_max_points_branches, generate_noisy_normals
from tree_plane_predictor import tree_points_to_array, PointEncoder
from cascade_transform import apply_cascade_transform_to_branches
import os
# åˆ›å»ºä¸´æ—¶datasetå®ä¾‹æ¥ç”Ÿæˆæ›²é¢
class TempDataset:
    def _generate_surface_grid(self, centerline_points, main_direction, grid_size, point_spacing):
        """
        åœ¨ä»¥centerline_pointsä¸ºä¸­è½´çš„æ›²é¢ä¸Šç”Ÿæˆç½‘æ ¼ç‚¹
        
        Args:
            centerline_points: ä¸­è½´çº¿ä¸Šçš„ç‚¹ (N, 3)
            main_direction: ä¸­è½´çº¿ä¸»æ–¹å‘
            grid_size: ç½‘æ ¼å¤§å°
            point_spacing: ç‚¹é—´è·
        
        Returns:
            surface_points: æ›²é¢ä¸Šçš„ç½‘æ ¼ç‚¹ (grid_size, grid_size, 3)
        """
        # è®¡ç®—ç½‘æ ¼èŒƒå›´
        grid_extent = (grid_size - 1) * point_spacing / 2
        
        # æ²¿ä¸­è½´çº¿ç”Ÿæˆç­‰è·ä½ç½®
        axis_positions = []
        for i in range(grid_size):
            t = i / (grid_size - 1)  # 0 åˆ° 1
            axis_pos = self._interpolate_on_centerline(centerline_points, t)
            axis_positions.append(axis_pos)
        
        axis_positions = np.array(axis_positions)
        surface_points = np.zeros((grid_size, grid_size, 3))
        
        # ä¸ºæ¯ä¸ªè½´ä½ç½®æ„å»ºå‚ç›´å¹³é¢çš„åæ ‡ç³»
        for i, axis_pos in enumerate(axis_positions):
            # è®¡ç®—åœ¨è¯¥ä½ç½®å¤„ä¸­è½´çº¿çš„åˆ‡çº¿æ–¹å‘
            if i == 0:
                tangent = axis_positions[1] - axis_positions[0]
            elif i == grid_size - 1:
                tangent = axis_positions[-1] - axis_positions[-2]
            else:
                tangent = axis_positions[i+1] - axis_positions[i-1]
            
            tangent = tangent / (np.linalg.norm(tangent) + 1e-8)
            
            # æ„å»ºå‚ç›´äºåˆ‡çº¿çš„ä¸¤ä¸ªæ­£äº¤åŸºå‘é‡
            if abs(np.dot(tangent, np.array([1, 0, 0]))) < 0.9:
                base_vector = np.array([1, 0, 0])
            else:
                base_vector = np.array([0, 1, 0])
            
            u_axis = np.cross(tangent, base_vector)
            u_axis = u_axis / (np.linalg.norm(u_axis) + 1e-8)
            
            v_axis = np.cross(tangent, u_axis)
            v_axis = v_axis / (np.linalg.norm(v_axis) + 1e-8)
            
            # ğŸ”„ ç»•åˆ‡çº¿å‘é‡æ—‹è½¬90åº¦
            u_axis_rotated = v_axis      # åŸæ¥çš„v_axisæˆä¸ºæ–°çš„u_axis
            v_axis_rotated = -u_axis     # åŸæ¥çš„u_axisçš„è´Ÿå€¼æˆä¸ºæ–°çš„v_axis
            
            # åœ¨å‚ç›´å¹³é¢ä¸Šç”Ÿæˆç½‘æ ¼ç‚¹
            for j in range(grid_size):
                # ä» -grid_extent åˆ° +grid_extent å‡åŒ€åˆ†å¸ƒ
                offset = (j / (grid_size - 1) - 0.5) * 2 * grid_extent
                
                # ä½¿ç”¨æ—‹è½¬åçš„åæ ‡ç³»åœ¨å‚ç›´å¹³é¢ä¸Šçš„ç‚¹
                point_on_surface = axis_pos + offset * u_axis_rotated
                
                # æ·»åŠ è½»å¾®çš„æ›²ç‡å˜åŒ–ï¼Œä½¿å…¶æ›´åƒçœŸå®çš„è¡€ç®¡æ›²é¢
                curvature_factor = 0.1 * abs(offset) * np.sin(i * np.pi / grid_size)
                point_on_surface += curvature_factor * v_axis_rotated
                
                surface_points[i, j] = point_on_surface
        
        return surface_points
    
    def _interpolate_on_centerline(self, centerline_points, t):
        if len(centerline_points) == 1:
            return centerline_points[0]
        
        cumulative_lengths = [0]
        for i in range(1, len(centerline_points)):
            dist = np.linalg.norm(centerline_points[i] - centerline_points[i-1])
            cumulative_lengths.append(cumulative_lengths[-1] + dist)
        
        total_length = cumulative_lengths[-1]
        target_length = t * total_length
        
        for i in range(len(cumulative_lengths) - 1):
            if cumulative_lengths[i] <= target_length <= cumulative_lengths[i+1]:
                segment_t = (target_length - cumulative_lengths[i]) / (cumulative_lengths[i+1] - cumulative_lengths[i])
                return centerline_points[i] + segment_t * (centerline_points[i+1] - centerline_points[i])
        
        if t <= 0:
            return centerline_points[0]
        else:
            return centerline_points[-1]
# --------- Noise schedule utilities ---------

def linear_beta_schedule(T:int, beta_start:float=1e-4, beta_end:float=2e-2):
    return torch.linspace(beta_start, beta_end, T)

def generate_plane_points(center, normal, plane_size=30.0, grid_size=32):
    """åœ¨ç»™å®šå¹³é¢ä¸Šç”Ÿæˆå‡åŒ€åˆ†å¸ƒçš„ç‚¹"""
    # ç”Ÿæˆå¹³é¢çš„ä¸¤ä¸ªæ­£äº¤åŸºå‘é‡
    helper = np.array([1.,0.,0.])
    if np.allclose(abs(np.dot(helper, normal)),1.0,atol=1e-3):
        helper=np.array([0.,1.,0.])
    v1=np.cross(normal,helper); v1/=np.linalg.norm(v1)
    v2=np.cross(normal,v1); v2/=np.linalg.norm(v2)
    
    # ç”Ÿæˆç½‘æ ¼ç‚¹
    g = np.linspace(-plane_size/2, plane_size/2, grid_size)
    u, v = np.meshgrid(g, g)
    
    # è®¡ç®—å¹³é¢ä¸Šçš„ç‚¹
    points = center + u[...,None]*v1 + v[...,None]*v2
    return points.reshape(-1, 3)  # (grid_size*grid_size, 3)


# --------- Dataset ---------
class TreeNormalDiffusionDataset(Dataset):
    def __init__(self, json_files: List[str], grid_size=32, point_spacing=0.2):
        self.files = json_files
        self.grid_size = grid_size
        self.point_spacing = point_spacing
        self.data = []
        self.targets = []
        for f in json_files:
            with open(f,'r') as fp:
                td=json.load(fp)
            # ç”Ÿæˆå¢å¼ºæ•°æ®
            augmented_trees = [td]
            for _ in range(3):  # ç”Ÿæˆ3ä¸ªå¢å¼ºç‰ˆæœ¬
                import copy
                td_aug = copy.deepcopy(td)
                td_aug["branches"] = apply_cascade_transform_to_branches(
                    td_aug["branches"],
                    max_offset=1.0,
                    rotation_range=30.0,
                    offset_strength=0.3,
                    rotation_strength=0.3
                )
                augmented_trees.append(td_aug)
            for td_aug in augmented_trees:
                pts = tree_points_to_array(td_aug)
                self.data.append(pts)
                trunk_pts, br1_pts, br2_pts = find_max_points_branches(td_aug)
                # è®¡ç®—ä¸¤ä¸ªåˆ†æ”¯å¯¹åº”ç‚¹çš„ä¸­ç‚¹ï¼Œæ„å»ºä¸­è½´çº¿
                min_len = min(len(br1_pts), len(br2_pts))
                if min_len > 0:
                    # å–ç›¸åŒæ•°é‡çš„ç‚¹æ¥è®¡ç®—ä¸­ç‚¹
                    br1_sampled = br1_pts[:min_len]
                    br2_sampled = br2_pts[:min_len]
                    midpoints = (br1_sampled + br2_sampled) / 2.0
                else:
                    # å¦‚æœæ²¡æœ‰åˆ†æ”¯ç‚¹ï¼Œä½¿ç”¨ä¸»å¹²æœ«ç«¯ä½œä¸ºä¸­ç‚¹
                    midpoints = np.array([trunk_pts[-1]])
                # æ„å»ºä¸­è½´çº¿ï¼šä¸»å¹²ç‚¹ + åˆ†æ”¯ä¸­ç‚¹
                centerline_points = np.vstack([trunk_pts, midpoints])
                # å¯¹ä¸­è½´çº¿ç‚¹è¿›è¡Œæ’åºï¼Œç¡®ä¿è¿ç»­æ€§
                centerline_center = centerline_points.mean(axis=0)
                centerline_centered = centerline_points - centerline_center
                # ä½¿ç”¨PCAæ‰¾åˆ°ä¸­è½´çº¿çš„ä¸»æ–¹å‘
                cov_matrix = np.cov(centerline_centered.T)
                eigenvals, eigenvecs = np.linalg.eig(cov_matrix)
                idx = np.argsort(eigenvals)[::-1]
                main_direction = eigenvecs[:, idx[0]]  # ä¸­è½´çº¿ä¸»æ–¹å‘
                # å°†ä¸­è½´çº¿ç‚¹æŠ•å½±åˆ°ä¸»æ–¹å‘ä¸Šå¹¶æ’åº
                projections = np.dot(centerline_centered, main_direction)
                sorted_indices = np.argsort(projections)
                sorted_centerline = centerline_points[sorted_indices]
                # ç”Ÿæˆæ›²é¢ä¸Šçš„32x32ç½‘æ ¼ç‚¹
                surface_grid_points = self._generate_surface_grid(
                    sorted_centerline, main_direction, grid_size, point_spacing
                )
                self.targets.append(surface_grid_points.astype(np.float32))
    
    def _generate_surface_grid(self, centerline_points, main_direction, grid_size, point_spacing):
        """
        åœ¨ä»¥centerline_pointsä¸ºä¸­è½´çš„æ›²é¢ä¸Šç”Ÿæˆ32x32ç½‘æ ¼ç‚¹
        
        Args:
            centerline_points: ä¸­è½´çº¿ä¸Šçš„ç‚¹ (N, 3)
            main_direction: ä¸­è½´çº¿ä¸»æ–¹å‘
            grid_size: ç½‘æ ¼å¤§å° (32)
            point_spacing: ç‚¹é—´è·
        
        Returns:
            surface_points: æ›²é¢ä¸Šçš„ç½‘æ ¼ç‚¹ (grid_size, grid_size, 3)
        """
        # è®¡ç®—ç½‘æ ¼èŒƒå›´
        grid_extent = (grid_size - 1) * point_spacing / 2
        
        # ç”Ÿæˆæ²¿ä¸­è½´çº¿æ–¹å‘çš„32ä¸ªä½ç½®
        centerline_start = centerline_points[0]
        centerline_end = centerline_points[-1]
        centerline_length = np.linalg.norm(centerline_end - centerline_start)
        
        # æ²¿ä¸­è½´çº¿ç”Ÿæˆ32ä¸ªç­‰è·ä½ç½®
        axis_positions = []
        for i in range(grid_size):
            t = i / (grid_size - 1)  # 0 åˆ° 1
            # åœ¨ä¸­è½´çº¿ä¸Šæ’å€¼
            axis_pos = self._interpolate_on_centerline(centerline_points, t)
            axis_positions.append(axis_pos)
        
        axis_positions = np.array(axis_positions)
        
        # ä¸ºæ¯ä¸ªè½´ä½ç½®æ„å»ºå‚ç›´å¹³é¢çš„åæ ‡ç³»
        surface_points = np.zeros((grid_size, grid_size, 3))
        
        for i, axis_pos in enumerate(axis_positions):
            # è®¡ç®—åœ¨è¯¥ä½ç½®å¤„ä¸­è½´çº¿çš„åˆ‡çº¿æ–¹å‘
            if i == 0:
                tangent = axis_positions[1] - axis_positions[0]
            elif i == grid_size - 1:
                tangent = axis_positions[-1] - axis_positions[-2]
            else:
                tangent = axis_positions[i+1] - axis_positions[i-1]
            
            tangent = tangent / (np.linalg.norm(tangent) + 1e-8)
            
            # æ„å»ºå‚ç›´äºåˆ‡çº¿çš„ä¸¤ä¸ªæ­£äº¤åŸºå‘é‡
            if abs(np.dot(tangent, np.array([1, 0, 0]))) < 0.9:
                base_vector = np.array([1, 0, 0])
            else:
                base_vector = np.array([0, 1, 0])
            
            u_axis = np.cross(tangent, base_vector)
            u_axis = u_axis / (np.linalg.norm(u_axis) + 1e-8)
            
            v_axis = np.cross(tangent, u_axis)
            v_axis = v_axis / (np.linalg.norm(v_axis) + 1e-8)
            
            # ç»•åˆ‡çº¿å‘é‡æ—‹è½¬90åº¦ï¼šäº¤æ¢u_axiså’Œv_axisï¼Œå¹¶å¯¹å…¶ä¸­ä¸€ä¸ªå–è´Ÿ
            # è¿™ç›¸å½“äºå°†åæ ‡ç³»ç»•tangentè½´æ—‹è½¬90åº¦
            u_axis_rotated = v_axis      # åŸæ¥çš„v_axisæˆä¸ºæ–°çš„u_axis
            v_axis_rotated = -u_axis     # åŸæ¥çš„u_axisçš„è´Ÿå€¼æˆä¸ºæ–°çš„v_axis
            
            # åœ¨å‚ç›´å¹³é¢ä¸Šç”Ÿæˆ32ä¸ªç‚¹ï¼ˆä¸€è¡Œï¼‰
            for j in range(grid_size):
                # ä» -grid_extent åˆ° +grid_extent å‡åŒ€åˆ†å¸ƒ
                offset = (j / (grid_size - 1) - 0.5) * 2 * grid_extent
                
                # ä½¿ç”¨æ—‹è½¬åçš„åæ ‡ç³»åœ¨å‚ç›´å¹³é¢ä¸Šçš„ç‚¹
                point_on_surface = axis_pos + offset * u_axis_rotated
                
                # æ·»åŠ è½»å¾®çš„æ›²ç‡å˜åŒ–ï¼Œä½¿å…¶æ›´åƒçœŸå®çš„è¡€ç®¡æ›²é¢
                curvature_factor = 0.1 * abs(offset) * np.sin(i * np.pi / grid_size)
                point_on_surface += curvature_factor * v_axis_rotated
                
                surface_points[i, j] = point_on_surface
        
        return surface_points
    
    def _interpolate_on_centerline(self, centerline_points, t):
        """
        åœ¨ä¸­è½´çº¿ä¸ŠæŒ‰å‚æ•°tæ’å€¼ (tåœ¨0åˆ°1ä¹‹é—´)
        """
        if len(centerline_points) == 1:
            return centerline_points[0]
        
        # è®¡ç®—ç´¯ç§¯å¼§é•¿
        cumulative_lengths = [0]
        for i in range(1, len(centerline_points)):
            dist = np.linalg.norm(centerline_points[i] - centerline_points[i-1])
            cumulative_lengths.append(cumulative_lengths[-1] + dist)
        
        total_length = cumulative_lengths[-1]
        target_length = t * total_length
        
        # æ‰¾åˆ°ç›®æ ‡é•¿åº¦å¯¹åº”çš„çº¿æ®µ
        for i in range(len(cumulative_lengths) - 1):
            if cumulative_lengths[i] <= target_length <= cumulative_lengths[i+1]:
                # åœ¨è¯¥çº¿æ®µå†…æ’å€¼
                segment_t = (target_length - cumulative_lengths[i]) / (cumulative_lengths[i+1] - cumulative_lengths[i])
                return centerline_points[i] + segment_t * (centerline_points[i+1] - centerline_points[i])
        
        # è¾¹ç•Œæƒ…å†µ
        if t <= 0:
            return centerline_points[0]
        else:
            return centerline_points[-1]
            
    def __len__(self):
        return len(self.files)
    def __getitem__(self, idx):
        pts = self.data[idx]
        target = self.targets[idx]  # (grid_size, grid_size, 3)
        # normalize xyz
        xyz = pts[:,:3]
        xyz = xyz - xyz.mean(0, keepdims=True)
        xyz = xyz/(xyz.std()+1e-6)
        ids = pts[:,3:5]/100.0
        feat = np.concatenate([xyz, ids], axis=1)
        
        # å°†ç›®æ ‡å±•å¹³ä¸ºä¸€ç»´å‘é‡
        target_flat = target.flatten()  # (grid_size*grid_size*3,)
        return torch.tensor(feat, dtype=torch.float32), torch.tensor(target_flat, dtype=torch.float32)

# --------- Conditioned Noise Predictor ---------
class CondNoisePredictor(nn.Module):
    def __init__(self, feat_dim=5, emb_dim=128, grid_size=32):
        super().__init__()
        self.grid_size = grid_size
        self.output_dim = grid_size * grid_size * 3  # 32*32*3 = 3072
        self.encoder = PointEncoder(feat_dim, emb_dim)
        self.time_fc = nn.Linear(1, emb_dim)
        self.cond_fc = nn.Linear(3, emb_dim)
        self.mlp = nn.Sequential(
            nn.Linear(emb_dim + self.output_dim, 256),
            nn.SiLU(),
            nn.Linear(256, 512),
            nn.SiLU(),
            nn.Linear(512, self.output_dim)
        )
    def forward(self, pts:torch.Tensor, noisy_points:torch.Tensor, t:torch.Tensor):
        # pts: (B,N,F)  noisy_points:(B,grid_size*grid_size*3) t:(B,)
        cond_raw = self.encoder(pts)           # (B,3)
        cond_emb = self.cond_fc(cond_raw)      # (B,emb_dim)
        time_emb = torch.sin(self.time_fc(t.float().unsqueeze(1)))  # (B,emb_dim)
        h = torch.cat([cond_emb + time_emb, noisy_points], dim=1)
        return self.mlp(h)

# --------- Training function ---------

def train_tree_diffusion(train_files: List[str], T:int=100, epochs:int=10000, batch_size:int=2, device='cpu', grid_size=32, point_spacing=0.2):
    # é¦–å…ˆéªŒè¯æ•°æ®é›†
    print("æ­£åœ¨éªŒè¯æ•°æ®é›†...")
    dataset = TreeNormalDiffusionDataset(train_files, grid_size, point_spacing)
    _validate_dataset(dataset, device)
    
    dl = DataLoader(dataset, batch_size=batch_size, shuffle=True)
    model = CondNoisePredictor(feat_dim=5, emb_dim=128, grid_size=grid_size).to(device)
    opt = torch.optim.Adam(model.parameters(), lr=1e-4)
    betas = linear_beta_schedule(T)
    
    # å¯è§†åŒ–ç›¸å…³å˜é‡
    viz_interval = 500  # æ¯500æ­¥å¯è§†åŒ–ä¸€æ¬¡
    viz_counter = 0
    
    # è®­ç»ƒç›‘æ§å˜é‡
    loss_history = []
    noise_error_history = []
    data_quality_metrics = []
    
    print(f"å¼€å§‹è®­ç»ƒ - æ•°æ®é›†å¤§å°: {len(dataset)}, æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    for ep in range(epochs):
        total=0;cnt=0
        epoch_losses = []
        epoch_noise_errors = []
        
        for feats, clean in dl:
            feats, clean = feats.to(device), clean.to(device)
            B = clean.shape[0]
            t = torch.randint(0, T, (B,), device=device)
            beta_t = betas[t].unsqueeze(1)
            # åœ¨å¾ªç¯ä¹‹å‰ç”Ÿæˆéšæœºå™ªå£°
            noise = torch.randn_like(clean)
            # è®¡ç®—æ¯ä¸€æ­¥çš„å™ªå£°å¢é‡
            noise_step = noise / T
            noisy = clean.clone()
            for step in range(T):
                # æŒ‰æ¯”ä¾‹åŠ å…¥å™ªå£°
                noisy = torch.sqrt(1-beta_t)*noisy + torch.sqrt(beta_t)*noise_step
            pred_noise = model(feats, noisy, t)
            loss = F.mse_loss(pred_noise, noise)
            opt.zero_grad(); loss.backward(); opt.step()
            
            # è®°å½•æŸå¤±å’Œå™ªå£°é¢„æµ‹è¯¯å·®
            total+=loss.item(); cnt+=1
            epoch_losses.append(loss.item())
            noise_error = F.mse_loss(pred_noise, noise).item()
            epoch_noise_errors.append(noise_error)
            
            # å•æ­¥å¯è§†åŒ–ç­–ç•¥
            viz_counter += 1
            if viz_counter % viz_interval == 0:
                _visualize_training_step(feats, clean, noisy, pred_noise, noise, t, ep, viz_counter, device)
                
        # è®°å½•epochçº§åˆ«çš„ç»Ÿè®¡ä¿¡æ¯
        avg_loss = total/cnt
        avg_noise_error = np.mean(epoch_noise_errors)
        loss_history.append(avg_loss)
        noise_error_history.append(avg_noise_error)
        
        # è®¡ç®—æ•°æ®è´¨é‡æŒ‡æ ‡
        if ep % 10 == 0:  # æ¯10ä¸ªepochè®¡ç®—ä¸€æ¬¡
            quality_metrics = _calculate_data_quality_metrics(dataset, device)
            data_quality_metrics.append(quality_metrics)
        
        if ep%100==0:
            print(f"Epoch {ep}/{epochs} loss {avg_loss:.6f} noise_error {avg_noise_error:.6f}")
            
            # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
            if len(loss_history) > 1:
                _plot_training_curves(loss_history, noise_error_history, data_quality_metrics, ep)
    
    # è®­ç»ƒç»“æŸåçš„æ€»ç»“
    print("\n=== è®­ç»ƒå®Œæˆæ€»ç»“ ===")
    print(f"æœ€ç»ˆæŸå¤±: {loss_history[-1]:.6f}")
    print(f"æœ€ç»ˆå™ªå£°é¢„æµ‹è¯¯å·®: {noise_error_history[-1]:.6f}")
    print(f"æŸå¤±ä¸‹é™: {loss_history[0] - loss_history[-1]:.6f}")
    
    return model, betas

def _validate_dataset(dataset, device):
    """
    éªŒè¯æ•°æ®é›†çš„æ­£ç¡®æ€§
    """
    print("\n=== æ•°æ®é›†éªŒè¯ ===")
    
    # æ£€æŸ¥æ•°æ®é›†å¤§å°
    print(f"æ•°æ®é›†å¤§å°: {len(dataset)}")
    
    # æ£€æŸ¥å‡ ä¸ªæ ·æœ¬
    sample_indices = np.random.choice(len(dataset), min(3, len(dataset)), replace=False)
    
    for i, idx in enumerate(sample_indices):
        print(f"\næ ·æœ¬ {i+1} (ç´¢å¼• {idx}):")
        
        feats, clean = dataset[idx]
        
        # æ£€æŸ¥ç‰¹å¾ç»´åº¦
        print(f"  ç‰¹å¾å½¢çŠ¶: {feats.shape}")
        print(f"  ç›®æ ‡å½¢çŠ¶: {clean.shape}")
        
        # æ£€æŸ¥æ•°å€¼èŒƒå›´
        feats_np = feats.numpy()
        clean_np = clean.numpy()
        
        print(f"  ç‰¹å¾èŒƒå›´: X[{feats_np[:, 0].min():.3f}, {feats_np[:, 0].max():.3f}], "
              f"Y[{feats_np[:, 1].min():.3f}, {feats_np[:, 1].max():.3f}], "
              f"Z[{feats_np[:, 2].min():.3f}, {feats_np[:, 2].max():.3f}]")
        
        grid_size = int(np.sqrt(clean.shape[0] // 3))
        clean_reshaped = clean_np.reshape(grid_size, grid_size, 3)
        print(f"  ç›®æ ‡èŒƒå›´: X[{clean_reshaped[:, :, 0].min():.3f}, {clean_reshaped[:, :, 0].max():.3f}], "
              f"Y[{clean_reshaped[:, :, 1].min():.3f}, {clean_reshaped[:, :, 1].max():.3f}], "
              f"Z[{clean_reshaped[:, :, 2].min():.3f}, {clean_reshaped[:, :, 2].max():.3f}]")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰NaNæˆ–æ— ç©·å¤§å€¼
        if np.any(np.isnan(feats_np)) or np.any(np.isnan(clean_np)):
            print("  âš ï¸  è­¦å‘Š: å‘ç°NaNå€¼!")
        if np.any(np.isinf(feats_np)) or np.any(np.isinf(clean_np)):
            print("  âš ï¸  è­¦å‘Š: å‘ç°æ— ç©·å¤§å€¼!")
        
        # æ£€æŸ¥æ›²é¢è¿ç»­æ€§
        dx = np.gradient(clean_reshaped, axis=0)
        dy = np.gradient(clean_reshaped, axis=1)
        grad_magnitude = np.sqrt(np.sum(dx**2, axis=2) + np.sum(dy**2, axis=2))
        max_grad = np.max(grad_magnitude)
        print(f"  æœ€å¤§æ¢¯åº¦: {max_grad:.3f}")
        
        if max_grad > 10.0:
            print("  âš ï¸  è­¦å‘Š: æ›²é¢æ¢¯åº¦è¿‡å¤§ï¼Œå¯èƒ½å­˜åœ¨ä¸è¿ç»­")
    
    # å¯è§†åŒ–ç¬¬ä¸€ä¸ªæ ·æœ¬
    print("\næ­£åœ¨ç”ŸæˆéªŒè¯å¯è§†åŒ–...")
    feats, clean = dataset[0]
    feats = feats.unsqueeze(0).to(device)
    clean = clean.unsqueeze(0).to(device)
    
    _visualize_validation_sample(feats, clean, device)
    
    print("âœ… æ•°æ®é›†éªŒè¯å®Œæˆ")

def _visualize_validation_sample(feats, clean, device):
    """
    å¯è§†åŒ–éªŒè¯æ ·æœ¬
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    # æå–æ•°æ®
    feats_np = feats[0].cpu().numpy()
    original_points = feats_np[:, :3]
    
    grid_size = int(np.sqrt(clean.shape[1] // 3))
    clean_np = clean[0].cpu().numpy().reshape(grid_size, grid_size, 3)
    
    # åˆ›å»ºå¯è§†åŒ–
    fig = plt.figure(figsize=(15, 5))
    fig.suptitle('æ•°æ®é›†éªŒè¯å¯è§†åŒ–', fontsize=16)
    
    # åŸå§‹ç‚¹äº‘
    ax1 = fig.add_subplot(1, 3, 1, projection='3d')
    ax1.scatter(original_points[:, 0], original_points[:, 1], original_points[:, 2], 
               c='blue', s=1, alpha=0.6)
    ax1.set_title('åŸå§‹è¡€ç®¡ç‚¹äº‘')
    ax1.set_xlabel('X'); ax1.set_ylabel('Y'); ax1.set_zlabel('Z')
    
    # ç›®æ ‡æ›²é¢
    ax2 = fig.add_subplot(1, 3, 2, projection='3d')
    ax2.plot_surface(clean_np[:, :, 0], clean_np[:, :, 1], clean_np[:, :, 2], 
                    alpha=0.7, cmap='viridis')
    ax2.set_title('ç›®æ ‡æ›²é¢')
    ax2.set_xlabel('X'); ax2.set_ylabel('Y'); ax2.set_zlabel('Z')
    
    # ç‚¹äº‘ä¸æ›²é¢å¯¹æ¯”
    ax3 = fig.add_subplot(1, 3, 3, projection='3d')
    ax3.scatter(original_points[:, 0], original_points[:, 1], original_points[:, 2], 
               c='blue', s=1, alpha=0.6, label='åŸå§‹ç‚¹äº‘')
    ax3.plot_surface(clean_np[:, :, 0], clean_np[:, :, 1], clean_np[:, :, 2], 
                    alpha=0.3, cmap='viridis', label='ç›®æ ‡æ›²é¢')
    ax3.set_title('ç‚¹äº‘ä¸æ›²é¢å¯¹æ¯”')
    ax3.set_xlabel('X'); ax3.set_ylabel('Y'); ax3.set_zlabel('Z')
    ax3.legend()
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_dir = "training_visualization"
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, "dataset_validation.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"éªŒè¯å¯è§†åŒ–å·²ä¿å­˜: {save_path}")

def _calculate_data_quality_metrics(dataset, device):
    """
    è®¡ç®—æ•°æ®é›†è´¨é‡æŒ‡æ ‡
    """
    metrics = {}
    
    # éšæœºé‡‡æ ·å‡ ä¸ªæ ·æœ¬è¿›è¡Œåˆ†æ
    sample_indices = np.random.choice(len(dataset), min(5, len(dataset)), replace=False)
    
    surface_areas = []
    surface_smoothness = []
    point_cloud_coverage = []
    
    for idx in sample_indices:
        feats, clean = dataset[idx]
        feats = feats.unsqueeze(0).to(device)
        clean = clean.unsqueeze(0).to(device)
        
        # è®¡ç®—æ›²é¢é¢ç§¯
        grid_size = int(np.sqrt(clean.shape[1] // 3))
        clean_reshaped = clean[0].cpu().numpy().reshape(grid_size, grid_size, 3)
        
        # è®¡ç®—æ›²é¢é¢ç§¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        dx = np.gradient(clean_reshaped, axis=0)
        dy = np.gradient(clean_reshaped, axis=1)
        area_elements = np.sqrt(np.sum(dx**2, axis=2) + np.sum(dy**2, axis=2))
        surface_area = np.sum(area_elements)
        surface_areas.append(surface_area)
        
        # è®¡ç®—æ›²é¢å¹³æ»‘åº¦
        laplacian = np.gradient(np.gradient(clean_reshaped, axis=0), axis=0) + \
                   np.gradient(np.gradient(clean_reshaped, axis=1), axis=1)
        smoothness = np.mean(np.linalg.norm(laplacian, axis=2))
        surface_smoothness.append(smoothness)
        
        # è®¡ç®—ç‚¹äº‘è¦†ç›–åº¦
        original_points = feats[0, :, :3].cpu().numpy()
        surface_center = np.mean(clean_reshaped, axis=(0, 1))
        distances = np.linalg.norm(original_points - surface_center, axis=1)
        coverage = np.mean(distances < np.std(distances) * 2)
        point_cloud_coverage.append(coverage)
    
    metrics['avg_surface_area'] = np.mean(surface_areas)
    metrics['avg_smoothness'] = np.mean(surface_smoothness)
    metrics['avg_coverage'] = np.mean(point_cloud_coverage)
    
    return metrics

def _plot_training_curves(loss_history, noise_error_history, data_quality_metrics, current_epoch):
    """
    ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    """
    import matplotlib.pyplot as plt
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle(f'è®­ç»ƒç›‘æ§ - Epoch {current_epoch}', fontsize=16)
    
    # æŸå¤±æ›²çº¿
    axes[0, 0].plot(loss_history, 'b-', label='æ€»æŸå¤±')
    axes[0, 0].set_title('è®­ç»ƒæŸå¤±')
    axes[0, 0].set_xlabel('Epoch')
    axes[0, 0].set_ylabel('Loss')
    axes[0, 0].legend()
    axes[0, 0].grid(True)
    
    # å™ªå£°é¢„æµ‹è¯¯å·®
    axes[0, 1].plot(noise_error_history, 'r-', label='å™ªå£°é¢„æµ‹è¯¯å·®')
    axes[0, 1].set_title('å™ªå£°é¢„æµ‹è¯¯å·®')
    axes[0, 1].set_xlabel('Epoch')
    axes[0, 1].set_ylabel('MSE')
    axes[0, 1].legend()
    axes[0, 1].grid(True)
    
    # æ•°æ®è´¨é‡æŒ‡æ ‡
    if data_quality_metrics:
        epochs_quality = list(range(0, len(data_quality_metrics) * 10, 10))
        surface_areas = [m['avg_surface_area'] for m in data_quality_metrics]
        smoothness = [m['avg_smoothness'] for m in data_quality_metrics]
        
        axes[1, 0].plot(epochs_quality, surface_areas, 'g-', label='å¹³å‡æ›²é¢é¢ç§¯')
        axes[1, 0].set_title('æ•°æ®è´¨é‡ - æ›²é¢é¢ç§¯')
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('é¢ç§¯')
        axes[1, 0].legend()
        axes[1, 0].grid(True)
        
        axes[1, 1].plot(epochs_quality, smoothness, 'm-', label='å¹³å‡å¹³æ»‘åº¦')
        axes[1, 1].set_title('æ•°æ®è´¨é‡ - æ›²é¢å¹³æ»‘åº¦')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('å¹³æ»‘åº¦')
        axes[1, 1].legend()
        axes[1, 1].grid(True)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_dir = "training_visualization"
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"training_curves_{current_epoch}.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")

def _visualize_training_step(feats, clean, noisy, pred_noise, true_noise, t, epoch, step, device):
    """
    å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ä¸­çš„å•æ­¥æ•°æ®ï¼Œç”¨äºç›‘æµ‹è®­ç»ƒæ­£ç¡®æ€§
    
    Args:
        feats: è¾“å…¥ç‰¹å¾ (B, N, F)
        clean: å¹²å‡€çš„ç›®æ ‡æ›²é¢ (B, grid_size*grid_size*3)
        noisy: åŠ å™ªå£°çš„æ›²é¢ (B, grid_size*grid_size*3)
        pred_noise: é¢„æµ‹çš„å™ªå£° (B, grid_size*grid_size*3)
        true_noise: çœŸå®çš„å™ªå£° (B, grid_size*grid_size*3)
        t: æ—¶é—´æ­¥ (B,)
        epoch: å½“å‰epoch
        step: å½“å‰æ­¥æ•°
        device: è®¾å¤‡
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    # åªå¯è§†åŒ–ç¬¬ä¸€ä¸ªæ ·æœ¬
    batch_idx = 0
    grid_size = int(np.sqrt(clean.shape[1] // 3))
    
    # å°†å¼ é‡è½¬æ¢ä¸ºnumpyæ•°ç»„å¹¶é‡å¡‘
    clean_np = clean[batch_idx].cpu().detach().numpy().reshape(grid_size, grid_size, 3)
    noisy_np = noisy[batch_idx].cpu().detach().numpy().reshape(grid_size, grid_size, 3)
    pred_noise_np = pred_noise[batch_idx].cpu().detach().numpy().reshape(grid_size, grid_size, 3)
    true_noise_np = true_noise[batch_idx].cpu().detach().numpy().reshape(grid_size, grid_size, 3)
    
    # æå–åŸå§‹ç‚¹äº‘æ•°æ®
    feats_np = feats[batch_idx].cpu().detach().numpy()
    original_points = feats_np[:, :3]  # åªå–xyzåæ ‡
    
    # åˆ›å»ºå­å›¾
    fig = plt.figure(figsize=(20, 12))
    fig.suptitle(f'è®­ç»ƒæ­¥éª¤å¯è§†åŒ– - Epoch {epoch}, Step {step}, Time Step {t[batch_idx].item()}', fontsize=16)
    
    # 1. åŸå§‹ç‚¹äº‘
    ax1 = fig.add_subplot(2, 3, 1, projection='3d')
    ax1.scatter(original_points[:, 0], original_points[:, 1], original_points[:, 2], 
               c='blue', s=1, alpha=0.6, label='åŸå§‹ç‚¹äº‘')
    ax1.set_title('åŸå§‹è¡€ç®¡ç‚¹äº‘')
    ax1.set_xlabel('X'); ax1.set_ylabel('Y'); ax1.set_zlabel('Z')
    ax1.legend()
    
    # 2. ç›®æ ‡æ›²é¢ (clean)
    ax2 = fig.add_subplot(2, 3, 2, projection='3d')
    ax2.plot_surface(clean_np[:, :, 0], clean_np[:, :, 1], clean_np[:, :, 2], 
                    alpha=0.7, cmap='viridis')
    ax2.set_title('ç›®æ ‡æ›²é¢ (Label)')
    ax2.set_xlabel('X'); ax2.set_ylabel('Y'); ax2.set_zlabel('Z')
    
    # 3. åŠ å™ªå£°çš„æ›²é¢
    ax3 = fig.add_subplot(2, 3, 3, projection='3d')
    ax3.plot_surface(noisy_np[:, :, 0], noisy_np[:, :, 1], noisy_np[:, :, 2], 
                    alpha=0.7, cmap='plasma')
    ax3.set_title('åŠ å™ªå£°æ›²é¢ (Input)')
    ax3.set_xlabel('X'); ax3.set_ylabel('Y'); ax3.set_zlabel('Z')
    
    # 4. çœŸå®å™ªå£°
    ax4 = fig.add_subplot(2, 3, 4, projection='3d')
    ax4.plot_surface(true_noise_np[:, :, 0], true_noise_np[:, :, 1], true_noise_np[:, :, 2], 
                    alpha=0.7, cmap='coolwarm')
    ax4.set_title('çœŸå®å™ªå£° (Ground Truth)')
    ax4.set_xlabel('X'); ax4.set_ylabel('Y'); ax4.set_zlabel('Z')
    
    # 5. é¢„æµ‹å™ªå£°
    ax5 = fig.add_subplot(2, 3, 5, projection='3d')
    ax5.plot_surface(pred_noise_np[:, :, 0], pred_noise_np[:, :, 1], pred_noise_np[:, :, 2], 
                    alpha=0.7, cmap='coolwarm')
    ax5.set_title('é¢„æµ‹å™ªå£° (Prediction)')
    ax5.set_xlabel('X'); ax5.set_ylabel('Y'); ax5.set_zlabel('Z')
    
    # 6. å™ªå£°å·®å¼‚ (é¢„æµ‹ - çœŸå®)
    noise_diff = pred_noise_np - true_noise_np
    ax6 = fig.add_subplot(2, 3, 6, projection='3d')
    im = ax6.plot_surface(noise_diff[:, :, 0], noise_diff[:, :, 1], noise_diff[:, :, 2], 
                         alpha=0.7, cmap='RdBu')
    ax6.set_title('å™ªå£°é¢„æµ‹è¯¯å·®')
    ax6.set_xlabel('X'); ax6.set_ylabel('Y'); ax6.set_zlabel('Z')
    
    # æ·»åŠ é¢œè‰²æ¡
    fig.colorbar(im, ax=ax6, shrink=0.5, aspect=5)
    
    # è®¡ç®—å’Œæ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    noise_mse = np.mean((pred_noise_np - true_noise_np) ** 2)
    noise_mae = np.mean(np.abs(pred_noise_np - true_noise_np))
    
    # åœ¨å›¾ä¸Šæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    stats_text = f'å™ªå£°MSE: {noise_mse:.6f}\nå™ªå£°MAE: {noise_mae:.6f}'
    fig.text(0.02, 0.02, stats_text, fontsize=10, bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_dir = "training_visualization"
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"training_step_{epoch}_{step}.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    
    print(f"è®­ç»ƒå¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    print(f"å™ªå£°é¢„æµ‹è¯¯å·® - MSE: {noise_mse:.6f}, MAE: {noise_mae:.6f}")
    
    # æ£€æŸ¥æ•°æ®åˆç†æ€§
    _check_training_data_validity(clean_np, noisy_np, pred_noise_np, true_noise_np, original_points)
    
    plt.close()

def _check_training_data_validity(clean, noisy, pred_noise, true_noise, original_points):
    """
    æ£€æŸ¥è®­ç»ƒæ•°æ®çš„åˆç†æ€§
    
    Args:
        clean: ç›®æ ‡æ›²é¢
        noisy: åŠ å™ªå£°æ›²é¢
        pred_noise: é¢„æµ‹å™ªå£°
        true_noise: çœŸå®å™ªå£°
        original_points: åŸå§‹ç‚¹äº‘
    """
    print("\n=== è®­ç»ƒæ•°æ®åˆç†æ€§æ£€æŸ¥ ===")
    
    # 1. æ£€æŸ¥æ›²é¢å½¢çŠ¶
    clean_range = np.ptp(clean, axis=(0, 1))  # æ¯ä¸ªç»´åº¦çš„èŒƒå›´
    noisy_range = np.ptp(noisy, axis=(0, 1))
    print(f"ç›®æ ‡æ›²é¢èŒƒå›´: X[{clean_range[0]:.3f}], Y[{clean_range[1]:.3f}], Z[{clean_range[2]:.3f}]")
    print(f"å™ªå£°æ›²é¢èŒƒå›´: X[{noisy_range[0]:.3f}], Y[{noisy_range[1]:.3f}], Z[{noisy_range[2]:.3f}]")
    
    # 2. æ£€æŸ¥å™ªå£°å¹…åº¦
    noise_magnitude = np.linalg.norm(true_noise, axis=2)
    pred_magnitude = np.linalg.norm(pred_noise, axis=2)
    print(f"çœŸå®å™ªå£°å¹…åº¦: å‡å€¼={np.mean(noise_magnitude):.3f}, æ ‡å‡†å·®={np.std(noise_magnitude):.3f}")
    print(f"é¢„æµ‹å™ªå£°å¹…åº¦: å‡å€¼={np.mean(pred_magnitude):.3f}, æ ‡å‡†å·®={np.std(pred_magnitude):.3f}")
    
    # 3. æ£€æŸ¥ç‚¹äº‘ä¸æ›²é¢çš„å…³ç³»
    original_center = np.mean(original_points, axis=0)
    surface_center = np.mean(clean, axis=(0, 1))
    distance = np.linalg.norm(original_center - surface_center)
    print(f"åŸå§‹ç‚¹äº‘ä¸­å¿ƒä¸æ›²é¢ä¸­å¿ƒè·ç¦»: {distance:.3f}")
    
    # 4. æ£€æŸ¥æ›²é¢è¿ç»­æ€§
    clean_grad_x = np.gradient(clean, axis=0)
    clean_grad_y = np.gradient(clean, axis=1)
    grad_magnitude = np.sqrt(np.sum(clean_grad_x**2 + clean_grad_y**2, axis=2))
    print(f"æ›²é¢æ¢¯åº¦å¹…åº¦: å‡å€¼={np.mean(grad_magnitude):.3f}, æœ€å¤§å€¼={np.max(grad_magnitude):.3f}")
    
    # 5. æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼
    clean_std = np.std(clean, axis=(0, 1))
    noisy_std = np.std(noisy, axis=(0, 1))
    print(f"ç›®æ ‡æ›²é¢æ ‡å‡†å·®: X[{clean_std[0]:.3f}], Y[{clean_std[1]:.3f}], Z[{clean_std[2]:.3f}]")
    print(f"å™ªå£°æ›²é¢æ ‡å‡†å·®: X[{noisy_std[0]:.3f}], Y[{noisy_std[1]:.3f}], Z[{noisy_std[2]:.3f}]")
    
    # 6. åˆç†æ€§åˆ¤æ–­
    issues = []
    if distance > 5.0:
        issues.append("åŸå§‹ç‚¹äº‘ä¸æ›²é¢ä¸­å¿ƒè·ç¦»è¿‡å¤§")
    if np.max(grad_magnitude) > 10.0:
        issues.append("æ›²é¢æ¢¯åº¦è¿‡å¤§ï¼Œå¯èƒ½å­˜åœ¨ä¸è¿ç»­")
    if np.any(clean_std > 5.0):
        issues.append("ç›®æ ‡æ›²é¢æ ‡å‡†å·®è¿‡å¤§")
    if np.mean(noise_magnitude) > 2.0:
        issues.append("å™ªå£°å¹…åº¦è¿‡å¤§")
    
    if issues:
        print("âš ï¸  å‘ç°æ½œåœ¨é—®é¢˜:")
        for issue in issues:
            print(f"  - {issue}")
    else:
        print("âœ… æ•°æ®çœ‹èµ·æ¥åˆç†")
    
    print("=" * 40)

# --------- Denoise ---------

def denoise_with_tree(tree_json:str, model:CondNoisePredictor, betas:torch.Tensor, device='cpu', grid_size=32, point_spacing=0.2):
    with open(tree_json,'r') as fp:
        td=json.load(fp)
    pts_arr = tree_points_to_array(td)
    xyz = pts_arr[:,:3]
    xyz = xyz-xyz.mean(0,keepdims=True)
    xyz = xyz/(xyz.std()+1e-6)
    ids = pts_arr[:,3:5]/100.0
    feats = torch.tensor(np.concatenate([xyz,ids],axis=1)[None,...],dtype=torch.float32,device=device)
    T = betas.shape[0]
    
    # è·å–ä¸»å¹²ç‚¹å’Œåˆ†æ”¯ç‚¹
    trunk_pts, br1_pts, br2_pts = find_max_points_branches(td)
    all_branch_pts = np.vstack([br1_pts, br2_pts])
    
    # 1. è®¡ç®—æ‰€æœ‰ç‚¹çš„ä¸­å¿ƒä½œä¸ºå¹³é¢ä¸­å¿ƒ
    all_points = np.vstack([trunk_pts, br1_pts, br2_pts])
    plane_center = all_points.mean(axis=0)
    
    # 2. æ‰¾åˆ°ç»è¿‡åˆ†æ”¯æœ€å¤šçš„å¹³é¢ï¼ˆåˆ†æ”¯ç‚¹çš„ä¸»å¹³é¢ï¼‰
    branch_center = all_branch_pts.mean(axis=0)
    branch_centered = all_branch_pts - branch_center
    
    # è®¡ç®—åˆ†æ”¯ç‚¹çš„ä¸»å¹³é¢æ³•å‘é‡
    if len(branch_centered) >= 3:
        branch_cov = np.cov(branch_centered.T)
        branch_eigenvals, branch_eigenvecs = np.linalg.eigh(branch_cov)
        branch_idx = np.argsort(branch_eigenvals)[::-1]
        
        # åˆ†æ”¯ä¸»å¹³é¢ç”±å‰ä¸¤ä¸ªä¸»æˆåˆ†ç¡®å®šï¼Œæ³•å‘é‡æ˜¯ç¬¬ä¸‰ä¸ªä¸»æˆåˆ†
        branch_plane_normal = branch_eigenvecs[:, branch_idx[2]]  # æœ€å°ç‰¹å¾å€¼å¯¹åº”æ–¹å‘
    else:
        # å¦‚æœåˆ†æ”¯ç‚¹å¤ªå°‘ï¼Œä½¿ç”¨é»˜è®¤æ³•å‘é‡
        branch_plane_normal = np.array([0, 0, 1])
    
    # ç¡®ä¿æ³•å‘é‡æ˜¯å•ä½å‘é‡
    branch_plane_normal = branch_plane_normal / np.linalg.norm(branch_plane_normal)
    
    # 3. æ‰¾åˆ°ä¸åˆ†æ”¯å¹³é¢å‚ç›´ä¸”ç»è¿‡ä¸»å¹²æœ€å¤šçš„å¹³é¢
    trunk_center = trunk_pts.mean(axis=0)
    trunk_centered = trunk_pts - trunk_center
    
    # å°†ä¸»å¹²ç‚¹æŠ•å½±åˆ°å‚ç›´äºåˆ†æ”¯å¹³é¢æ³•å‘é‡çš„ç©ºé—´ä¸­
    projection_matrix = np.eye(3) - np.outer(branch_plane_normal, branch_plane_normal)
    trunk_projected = trunk_centered @ projection_matrix.T
    
    # åœ¨æŠ•å½±ç©ºé—´ä¸­æ‰¾ä¸»å¹²ç‚¹çš„ä¸»æ–¹å‘
    if len(trunk_projected) >= 2:
        trunk_proj_cov = np.cov(trunk_projected.T)
        trunk_eigenvals, trunk_eigenvecs = np.linalg.eigh(trunk_proj_cov)
        trunk_idx = np.argsort(trunk_eigenvals)[::-1]
        
        # ä¸»å¹²åœ¨æŠ•å½±ç©ºé—´ä¸­çš„ä¸»æ–¹å‘
        trunk_main_dir_projected = trunk_eigenvecs[:, trunk_idx[0]]
    else:
        trunk_main_dir_projected = np.array([1, 0, 0])
        trunk_main_dir_projected = trunk_main_dir_projected - np.dot(trunk_main_dir_projected, branch_plane_normal) * branch_plane_normal
    
    # ç¡®ä¿ä¸»å¹²ä¸»æ–¹å‘æ˜¯å•ä½å‘é‡
    trunk_main_dir_projected = trunk_main_dir_projected / (np.linalg.norm(trunk_main_dir_projected) + 1e-8)
    
    # 4. æ„å»ºåˆå§‹å¹³é¢çš„åæ ‡ç³»
    plane_normal = branch_plane_normal
    u_axis = trunk_main_dir_projected
    v_axis = np.cross(plane_normal, u_axis)
    v_axis = v_axis / (np.linalg.norm(v_axis) + 1e-8)
    u_axis = np.cross(v_axis, plane_normal)
    u_axis = u_axis / (np.linalg.norm(u_axis) + 1e-8)
    
    # 5. åœ¨å¹³é¢ä¸Šç”Ÿæˆ32x32çš„æ­£æ–¹å½¢ç½‘æ ¼ï¼Œé—´éš”ä¸ºpoint_spacing
    grid_extent = (grid_size - 1) * point_spacing / 2
    u_coords = np.linspace(-grid_extent, grid_extent, grid_size)
    v_coords = np.linspace(-grid_extent, grid_extent, grid_size)
    U, V = np.meshgrid(u_coords, v_coords)
    
    # å°†ç½‘æ ¼ç‚¹è½¬æ¢åˆ°3Dç©ºé—´
    grid_points = []
    for i in range(grid_size):
        for j in range(grid_size):
            point_3d = plane_center + U[i,j] * u_axis + V[i,j] * v_axis
            grid_points.append(point_3d)
    
    # è½¬æ¢ä¸ºtorch tensor
    initial_points = np.array(grid_points).flatten()
    x = torch.tensor(initial_points, dtype=torch.float32, device=device).unsqueeze(0)
    
    print(f"åˆå§‹å¹³é¢ä¿¡æ¯:")
    print(f"  å¹³é¢ä¸­å¿ƒ: {plane_center}")
    print(f"  åˆ†æ”¯å¹³é¢æ³•å‘é‡: {branch_plane_normal}")
    print(f"  ä¸»å¹²ä¸»æ–¹å‘: {trunk_main_dir_projected}")
    print(f"  å¹³é¢æ³•å‘é‡: {plane_normal}")
    print(f"  ç½‘æ ¼èŒƒå›´: {grid_extent*2:.2f} x {grid_extent*2:.2f}, ç‚¹é—´è·: {point_spacing}")
    
    with torch.no_grad():
        for t_inv in range(T-1,-1,-1):
            t=torch.tensor([t_inv],device=device)
            beta=betas[t_inv]
            pred_noise = model(feats, x, t)
            x = (x - torch.sqrt(beta)*pred_noise)/torch.sqrt(1-beta)
    return x.squeeze().cpu().numpy().reshape(grid_size, grid_size, 3)

# --------- Denoise with GIF ---------

def denoise_with_gif(tree_json:str, model:CondNoisePredictor, betas:torch.Tensor, gif_path:str='denoise.gif', device='cpu', grid_size=32, point_spacing=0.2):
    """å¯è§†åŒ–32*32ä¸ªç‚¹åœ¨å»å™ªè¿‡ç¨‹ä¸­çš„ç§»åŠ¨"""
    import imageio, matplotlib.pyplot as plt
    with open(tree_json,'r') as fp:
        td=json.load(fp)
    pts_arr = tree_points_to_array(td)
    xyz = pts_arr[:,:3]
    center = xyz.mean(axis=0)
    # normalize feats same as before
    xyz_n = xyz-center
    xyz_n = xyz_n/(xyz_n.std()+1e-6)
    ids = pts_arr[:,3:5]/100.0
    feats = torch.tensor(np.concatenate([xyz_n,ids],axis=1)[None,...],dtype=torch.float32,device=device)
    T = betas.shape[0]
    
    # è·å–ä¸»å¹²ç‚¹å’Œåˆ†æ”¯ç‚¹
    trunk_pts, br1_pts, br2_pts = find_max_points_branches(td)
    all_branch_pts = np.vstack([br1_pts, br2_pts])
    
    # 1. è®¡ç®—æ‰€æœ‰ç‚¹çš„ä¸­å¿ƒä½œä¸ºå¹³é¢ä¸­å¿ƒ
    all_points = np.vstack([trunk_pts, br1_pts, br2_pts])
    plane_center = all_points.mean(axis=0)
    
    # 2. æ‰¾åˆ°ç»è¿‡åˆ†æ”¯æœ€å¤šçš„å¹³é¢ï¼ˆåˆ†æ”¯ç‚¹çš„ä¸»å¹³é¢ï¼‰
    branch_center = all_branch_pts.mean(axis=0)
    branch_centered = all_branch_pts - branch_center
    
    # è®¡ç®—åˆ†æ”¯ç‚¹çš„ä¸»å¹³é¢æ³•å‘é‡
    if len(branch_centered) >= 3:
        branch_cov = np.cov(branch_centered.T)
        branch_eigenvals, branch_eigenvecs = np.linalg.eigh(branch_cov)
        branch_idx = np.argsort(branch_eigenvals)[::-1]
        
        # åˆ†æ”¯ä¸»å¹³é¢ç”±å‰ä¸¤ä¸ªä¸»æˆåˆ†ç¡®å®šï¼Œæ³•å‘é‡æ˜¯ç¬¬ä¸‰ä¸ªä¸»æˆåˆ†
        branch_plane_normal = branch_eigenvecs[:, branch_idx[2]]  # æœ€å°ç‰¹å¾å€¼å¯¹åº”æ–¹å‘
    else:
        # å¦‚æœåˆ†æ”¯ç‚¹å¤ªå°‘ï¼Œä½¿ç”¨é»˜è®¤æ³•å‘é‡
        branch_plane_normal = np.array([0, 0, 1])
    
    # ç¡®ä¿æ³•å‘é‡æ˜¯å•ä½å‘é‡
    branch_plane_normal = branch_plane_normal / np.linalg.norm(branch_plane_normal)
    
    # 3. æ‰¾åˆ°ä¸åˆ†æ”¯å¹³é¢å‚ç›´ä¸”ç»è¿‡ä¸»å¹²æœ€å¤šçš„å¹³é¢
    trunk_center = trunk_pts.mean(axis=0)
    trunk_centered = trunk_pts - trunk_center
    
    # å°†ä¸»å¹²ç‚¹æŠ•å½±åˆ°å‚ç›´äºåˆ†æ”¯å¹³é¢æ³•å‘é‡çš„ç©ºé—´ä¸­
    projection_matrix = np.eye(3) - np.outer(branch_plane_normal, branch_plane_normal)
    trunk_projected = trunk_centered @ projection_matrix.T
    
    # åœ¨æŠ•å½±ç©ºé—´ä¸­æ‰¾ä¸»å¹²ç‚¹çš„ä¸»æ–¹å‘
    if len(trunk_projected) >= 2:
        trunk_proj_cov = np.cov(trunk_projected.T)
        trunk_eigenvals, trunk_eigenvecs = np.linalg.eigh(trunk_proj_cov)
        trunk_idx = np.argsort(trunk_eigenvals)[::-1]
        
        # ä¸»å¹²åœ¨æŠ•å½±ç©ºé—´ä¸­çš„ä¸»æ–¹å‘
        trunk_main_dir_projected = trunk_eigenvecs[:, trunk_idx[0]]
    else:
        trunk_main_dir_projected = np.array([1, 0, 0])
        trunk_main_dir_projected = trunk_main_dir_projected - np.dot(trunk_main_dir_projected, branch_plane_normal) * branch_plane_normal
    
    # ç¡®ä¿ä¸»å¹²ä¸»æ–¹å‘æ˜¯å•ä½å‘é‡
    trunk_main_dir_projected = trunk_main_dir_projected / (np.linalg.norm(trunk_main_dir_projected) + 1e-8)
    
    # 4. æ„å»ºåˆå§‹å¹³é¢çš„åæ ‡ç³»
    plane_normal = branch_plane_normal
    u_axis = trunk_main_dir_projected
    v_axis = np.cross(plane_normal, u_axis)
    v_axis = v_axis / (np.linalg.norm(v_axis) + 1e-8)
    u_axis = np.cross(v_axis, plane_normal)
    u_axis = u_axis / (np.linalg.norm(u_axis) + 1e-8)
    
    # 5. åœ¨å¹³é¢ä¸Šç”Ÿæˆ32x32çš„æ­£æ–¹å½¢ç½‘æ ¼ï¼Œé—´éš”ä¸ºpoint_spacing
    grid_extent = (grid_size - 1) * point_spacing / 2
    u_coords = np.linspace(-grid_extent, grid_extent, grid_size)
    v_coords = np.linspace(-grid_extent, grid_extent, grid_size)
    U, V = np.meshgrid(u_coords, v_coords)
    
    # å°†ç½‘æ ¼ç‚¹è½¬æ¢åˆ°3Dç©ºé—´
    grid_points = []
    for i in range(grid_size):
        for j in range(grid_size):
            point_3d = plane_center + U[i,j] * u_axis + V[i,j] * v_axis
            grid_points.append(point_3d)
    
    # è½¬æ¢ä¸ºtorch tensor
    initial_points = np.array(grid_points).flatten()
    x = torch.tensor(initial_points, dtype=torch.float32, device=device).unsqueeze(0)
    
    print(f"GIFæ¨¡å¼ - åˆå§‹å¹³é¢ä¿¡æ¯:")
    print(f"  å¹³é¢ä¸­å¿ƒ: {plane_center}")
    print(f"  åˆ†æ”¯å¹³é¢æ³•å‘é‡: {branch_plane_normal}")
    print(f"  ä¸»å¹²ä¸»æ–¹å‘: {trunk_main_dir_projected}")
    print(f"  ç½‘æ ¼èŒƒå›´: {grid_extent*2:.2f} x {grid_extent*2:.2f}, ç‚¹é—´è·: {point_spacing}")
    
    frames=[]
    # precompute point sets for scatter
    branch_pts = np.vstack([br1_pts, br2_pts])

    with torch.no_grad():
        for t_inv in range(T-1,-1,-1):
            # å°†å½“å‰ç‚¹äº‘é‡å¡‘ä¸º(grid_size, grid_size, 3)æ ¼å¼
            current_points = x.squeeze().cpu().numpy().reshape(grid_size, grid_size, 3)
            
            fig = plt.figure(figsize=(12,8))
            ax = fig.add_subplot(111, projection='3d')
            
            # ç»˜åˆ¶åŸå§‹è¡€ç®¡ç‚¹
            ax.scatter(*trunk_pts.T,  c='blue',  s=2, alpha=0.6, label='ä¸»å¹²')
            ax.scatter(*br1_pts.T,    c='green', s=2, alpha=0.6, label='åˆ†æ”¯1')
            ax.scatter(*br2_pts.T,    c='red',   s=2, alpha=0.6, label='åˆ†æ”¯2')
            
            # ç»˜åˆ¶åˆå§‹å¹³é¢ï¼ˆåŠé€æ˜ï¼‰
            plane_size = grid_extent * 1.5
            plane_u = np.linspace(-plane_size, plane_size, 10)
            plane_v = np.linspace(-plane_size, plane_size, 10)
            Plane_U, Plane_V = np.meshgrid(plane_u, plane_v)
            
            plane_points = np.zeros((10, 10, 3))
            for i in range(10):
                for j in range(10):
                    plane_points[i, j] = plane_center + Plane_U[i,j] * u_axis + Plane_V[i,j] * v_axis
            
            ax.plot_surface(plane_points[:,:,0], plane_points[:,:,1], plane_points[:,:,2], 
                          alpha=0.2, color='yellow', label='åˆå§‹å¹³é¢')
            
            # ç»˜åˆ¶åˆ†æ”¯ä¸»å¹³é¢ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
            branch_plane_points = np.zeros((10, 10, 3))
            # æ„å»ºåˆ†æ”¯å¹³é¢çš„åæ ‡ç³»
            if abs(np.dot(branch_plane_normal, np.array([1, 0, 0]))) < 0.9:
                branch_u = np.cross(branch_plane_normal, np.array([1, 0, 0]))
            else:
                branch_u = np.cross(branch_plane_normal, np.array([0, 1, 0]))
            branch_u = branch_u / np.linalg.norm(branch_u)
            branch_v = np.cross(branch_plane_normal, branch_u)
            branch_v = branch_v / np.linalg.norm(branch_v)
            
            for i in range(10):
                for j in range(10):
                    branch_plane_points[i, j] = branch_center + Plane_U[i,j] * branch_u + Plane_V[i,j] * branch_v
            
            ax.plot_surface(branch_plane_points[:,:,0], branch_plane_points[:,:,1], branch_plane_points[:,:,2], 
                          alpha=0.1, color='cyan', label='åˆ†æ”¯ä¸»å¹³é¢')
            
            # ç»˜åˆ¶å½“å‰é¢„æµ‹çš„ç‚¹äº‘
            points_flat = current_points.reshape(-1, 3)
            ax.scatter(*points_flat.T, c='orange', s=3, alpha=0.8, label='æ‰©æ•£ç‚¹äº‘')
            
            # ç»˜åˆ¶ç‚¹äº‘çš„ç½‘æ ¼çº¿ä»¥æ˜¾ç¤ºç»“æ„
            for i in range(0, grid_size, 4):  # æ¯4è¡Œç»˜åˆ¶ä¸€æ¡çº¿
                line_points = current_points[i, :, :]
                ax.plot(line_points[:, 0], line_points[:, 1], line_points[:, 2], 
                       color='red', alpha=0.5, linewidth=1)
            for j in range(0, grid_size, 4):  # æ¯4åˆ—ç»˜åˆ¶ä¸€æ¡çº¿
                line_points = current_points[:, j, :]
                ax.plot(line_points[:, 0], line_points[:, 1], line_points[:, 2], 
                       color='red', alpha=0.5, linewidth=1)

            # è®¾ç½®è§†å›¾
            all_points_view = np.vstack([trunk_pts, br1_pts, br2_pts, points_flat])
            center_view = all_points_view.mean(axis=0)
            range_val = 40
            ax.set_xlim(center_view[0]-range_val, center_view[0]+range_val)
            ax.set_ylim(center_view[1]-range_val, center_view[1]+range_val)
            ax.set_zlim(center_view[2]-range_val, center_view[2]+range_val)
            ax.set_title(f'å»å™ªæ­¥éª¤: {T-t_inv-1}/{T}\nåˆå§‹å¹³é¢ï¼šç»è¿‡ä¸»å¹²æœ€å¤šï¼Œä¸åˆ†æ”¯å¹³é¢å‚ç›´\nç½‘æ ¼: {grid_size}x{grid_size}, é—´è·: {point_spacing}')
            ax.legend()
            
            fig.canvas.draw()
            frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')
            frame = frame.reshape(fig.canvas.get_width_height()[::-1]+(3,))
            frames.append(frame)
            plt.close(fig)

            # diffusion step
            if t_inv > 0:  # é¿å…æœ€åä¸€æ­¥
                t=torch.tensor([t_inv],device=device)
                beta=betas[t_inv]
                pred_noise = model(feats, x, t)
                x = (x - torch.sqrt(beta)*pred_noise)/torch.sqrt(1-beta)
                
    imageio.mimsave(gif_path, frames, fps=5)
    return x.squeeze().cpu().numpy().reshape(grid_size, grid_size, 3)

# --------- Visualization functions ---------

def safe_find_max_points_branches(tree_data):
    """å®‰å…¨çš„åˆ†æ”¯ç‚¹æå–å‡½æ•°ï¼Œå¤„ç†ä¸åŒçš„æ•°æ®ç»“æ„"""
    try:
        # å°è¯•ä½¿ç”¨åŸå§‹å‡½æ•°
        from visual import find_max_points_branches
        return find_max_points_branches(tree_data)
    except (KeyError, TypeError, IndexError) as e:
        print(f"åŸå§‹å‡½æ•°å¤±è´¥: {e}")
        print("ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æå–åˆ†æ”¯ç‚¹...")
        
        # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥ä»branchesåˆ—è¡¨ä¸­æå–
        if "branches" in tree_data and isinstance(tree_data["branches"], list):
            if len(tree_data["branches"]) > 0:
                trunk_branch = tree_data["branches"][0]
                trunk_points = np.array(trunk_branch["points"], dtype=np.float32)
                
                # è·å–åˆ†æ”¯
                children = trunk_branch.get("children", [])
                if len(children) >= 2:
                    # æŒ‰ç‚¹æ•°æ’åºï¼Œå–æœ€å¤§çš„ä¸¤ä¸ªåˆ†æ”¯
                    children_sorted = sorted(children, key=lambda b: len(b["points"]), reverse=True)
                    branch1_pts = np.array(children_sorted[0]["points"], dtype=np.float32)
                    branch2_pts = np.array(children_sorted[1]["points"], dtype=np.float32)
                elif len(children) == 1:
                    branch1_pts = np.array(children[0]["points"], dtype=np.float32)
                    branch2_pts = branch1_pts.copy()
                else:
                    # æ²¡æœ‰åˆ†æ”¯ï¼Œä½¿ç”¨ä¸»å¹²çš„å‰åŠéƒ¨åˆ†å’ŒååŠéƒ¨åˆ†
                    mid_idx = len(trunk_points) // 2
                    branch1_pts = trunk_points[:mid_idx]
                    branch2_pts = trunk_points[mid_idx:]
                
                return trunk_points, branch1_pts, branch2_pts
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤æ•°æ®
        print("æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤åˆ†æ”¯ç‚¹...")
        default_points = np.array([[0, 0, 0], [1, 0, 1], [0, 1, 2]], dtype=np.float32)
        return default_points, default_points, default_points

def visualize_generated_surface(tree_json: str, generated_points: np.ndarray, save_path: str = None, show_wireframe: bool = True, interactive: bool = True):
    """
    å¯è§†åŒ–ç”Ÿæˆçš„æ›²é¢ä¸åŸå§‹è¡€ç®¡æ ‘çš„å¯¹æ¯”
    
    Args:
        tree_json: è¡€ç®¡æ ‘jsonæ–‡ä»¶è·¯å¾„
        generated_points: ç”Ÿæˆçš„æ›²é¢ç‚¹ï¼Œå½¢çŠ¶ä¸º(grid_size, grid_size, 3)
        save_path: ä¿å­˜å›¾ç‰‡çš„è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™ä¸ä¿å­˜
        show_wireframe: æ˜¯å¦æ˜¾ç¤ºç½‘æ ¼çº¿
        interactive: æ˜¯å¦æ˜¾ç¤ºäº¤äº’å¼3Dç•Œé¢
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    # è¯»å–åŸå§‹è¡€ç®¡æ•°æ®
    with open(tree_json, 'r') as fp:
        td = json.load(fp)
    
    trunk_pts, br1_pts, br2_pts = safe_find_max_points_branches(td)
    
    fig = plt.figure(figsize=(15, 5))
    
    # å­å›¾1: åŸå§‹è¡€ç®¡æ ‘
    ax1 = fig.add_subplot(131, projection='3d')
    ax1.scatter(*trunk_pts.T, c='blue', s=3, alpha=0.8, label='ä¸»å¹²')
    ax1.scatter(*br1_pts.T, c='green', s=3, alpha=0.8, label='åˆ†æ”¯1')
    ax1.scatter(*br2_pts.T, c='red', s=3, alpha=0.8, label='åˆ†æ”¯2')
    ax1.set_title('åŸå§‹è¡€ç®¡æ ‘')
    ax1.legend()
    ax1.set_axis_off()
    
    # å­å›¾2: ç”Ÿæˆçš„æ›²é¢
    ax2 = fig.add_subplot(132, projection='3d')
    grid_size = generated_points.shape[0]
    
    # ç»˜åˆ¶æ›²é¢
    X, Y, Z = generated_points[:, :, 0], generated_points[:, :, 1], generated_points[:, :, 2]
    surf = ax2.plot_surface(X, Y, Z, alpha=0.7, cmap='viridis', linewidth=0.1)
    
    if show_wireframe:
        # æ·»åŠ ç½‘æ ¼çº¿
        for i in range(0, grid_size, 4):
            ax2.plot(X[i, :], Y[i, :], Z[i, :], 'k-', alpha=0.3, linewidth=0.5)
        for j in range(0, grid_size, 4):
            ax2.plot(X[:, j], Y[:, j], Z[:, j], 'k-', alpha=0.3, linewidth=0.5)
    
    ax2.set_title('ç”Ÿæˆçš„æ›²é¢')
    ax2.set_axis_off()
    
    # å­å›¾3: å åŠ æ˜¾ç¤º
    ax3 = fig.add_subplot(133, projection='3d')
    
    # ç»˜åˆ¶åŸå§‹è¡€ç®¡ç‚¹
    ax3.scatter(*trunk_pts.T, c='blue', s=2, alpha=0.6, label='ä¸»å¹²')
    ax3.scatter(*br1_pts.T, c='green', s=2, alpha=0.6, label='åˆ†æ”¯1')
    ax3.scatter(*br2_pts.T, c='red', s=2, alpha=0.6, label='åˆ†æ”¯2')
    
    # ç»˜åˆ¶ç”Ÿæˆçš„æ›²é¢ï¼ˆåŠé€æ˜ï¼‰
    ax3.plot_surface(X, Y, Z, alpha=0.3, color='orange')
    
    # ç»˜åˆ¶æ›²é¢è¾¹ç•Œçº¿
    ax3.plot(X[0, :], Y[0, :], Z[0, :], 'orange', linewidth=2, alpha=0.8)
    ax3.plot(X[-1, :], Y[-1, :], Z[-1, :], 'orange', linewidth=2, alpha=0.8)
    ax3.plot(X[:, 0], Y[:, 0], Z[:, 0], 'orange', linewidth=2, alpha=0.8)
    ax3.plot(X[:, -1], Y[:, -1], Z[:, -1], 'orange', linewidth=2, alpha=0.8)
    
    ax3.set_title('å åŠ å¯¹æ¯”')
    ax3.legend()
    ax3.set_axis_off()
    
    # ç»Ÿä¸€è®¾ç½®è§†å›¾èŒƒå›´
    all_points = np.vstack([trunk_pts, br1_pts, br2_pts])
    center = all_points.mean(axis=0)
    range_val = 30
    
    for ax in [ax1, ax2, ax3]:
        ax.set_xlim(center[0] - range_val, center[0] + range_val)
        ax.set_ylim(center[1] - range_val, center[1] + range_val)
        ax.set_zlim(center[2] - range_val, center[2] + range_val)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
    
    # æ˜¾ç¤ºäº¤äº’å¼ç•Œé¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if interactive:
        print("æ­£åœ¨æ‰“å¼€äº¤äº’å¼3Då¯è§†åŒ–ç•Œé¢...")
        print("æ‚¨å¯ä»¥:")
        print("- æ‹–æ‹½æ—‹è½¬è§†è§’")
        print("- æ»šè½®ç¼©æ”¾")
        print("- å…³é—­çª—å£ç»§ç»­ç¨‹åºæ‰§è¡Œ")
        plt.show()
    else:
        plt.close()

def analyze_surface_quality(tree_json: str, generated_points: np.ndarray):
    """
    åˆ†æç”Ÿæˆæ›²é¢çš„è´¨é‡æŒ‡æ ‡
    
    Args:
        tree_json: è¡€ç®¡æ ‘jsonæ–‡ä»¶è·¯å¾„
        generated_points: ç”Ÿæˆçš„æ›²é¢ç‚¹ï¼Œå½¢çŠ¶ä¸º(grid_size, grid_size, 3)
    
    Returns:
        dict: åŒ…å«å„ç§è´¨é‡æŒ‡æ ‡çš„å­—å…¸
    """
    
    # è¯»å–åŸå§‹è¡€ç®¡æ•°æ®
    with open(tree_json, 'r') as fp:
        td = json.load(fp)
    
    trunk_pts, br1_pts, br2_pts = safe_find_max_points_branches(td)
    all_vessel_points = np.vstack([trunk_pts, br1_pts, br2_pts])
    
    # å°†ç”Ÿæˆçš„æ›²é¢ç‚¹å±•å¹³
    surface_points = generated_points.reshape(-1, 3)
    
    # è®¡ç®—è´¨é‡æŒ‡æ ‡
    metrics = {}
    
    # 1. æ›²é¢è¦†ç›–èŒƒå›´ä¸è¡€ç®¡èŒƒå›´çš„æ¯”è¾ƒ
    vessel_bbox = {
        'min': all_vessel_points.min(axis=0),
        'max': all_vessel_points.max(axis=0),
        'range': all_vessel_points.max(axis=0) - all_vessel_points.min(axis=0)
    }
    
    surface_bbox = {
        'min': surface_points.min(axis=0),
        'max': surface_points.max(axis=0),
        'range': surface_points.max(axis=0) - surface_points.min(axis=0)
    }
    
    metrics['vessel_bbox'] = vessel_bbox
    metrics['surface_bbox'] = surface_bbox
    metrics['coverage_ratio'] = surface_bbox['range'] / vessel_bbox['range']
    
    # 2. æ›²é¢ä¸­å¿ƒä¸è¡€ç®¡ä¸­å¿ƒçš„è·ç¦»
    vessel_center = all_vessel_points.mean(axis=0)
    surface_center = surface_points.mean(axis=0)
    metrics['center_distance'] = np.linalg.norm(surface_center - vessel_center)
    
    # 3. è¡€ç®¡ç‚¹åˆ°æ›²é¢çš„æœ€å°è·ç¦»åˆ†å¸ƒ
    from scipy.spatial.distance import cdist
    distances = cdist(all_vessel_points, surface_points)
    min_distances = distances.min(axis=1)
    
    metrics['min_distance_stats'] = {
        'mean': min_distances.mean(),
        'std': min_distances.std(),
        'median': np.median(min_distances),
        'max': min_distances.max(),
        'min': min_distances.min()
    }
    
    # 4. æ›²é¢å¹³æ»‘åº¦ï¼ˆç›¸é‚»ç‚¹çš„è·ç¦»å˜åŒ–ï¼‰
    grid_size = generated_points.shape[0]
    
    # æ°´å¹³æ–¹å‘çš„å¹³æ»‘åº¦
    h_smoothness = []
    for i in range(grid_size):
        for j in range(grid_size - 1):
            dist = np.linalg.norm(generated_points[i, j+1] - generated_points[i, j])
            h_smoothness.append(dist)
    
    # å‚ç›´æ–¹å‘çš„å¹³æ»‘åº¦
    v_smoothness = []
    for i in range(grid_size - 1):
        for j in range(grid_size):
            dist = np.linalg.norm(generated_points[i+1, j] - generated_points[i, j])
            v_smoothness.append(dist)
    
    metrics['smoothness'] = {
        'horizontal_mean': np.mean(h_smoothness),
        'horizontal_std': np.std(h_smoothness),
        'vertical_mean': np.mean(v_smoothness),
        'vertical_std': np.std(v_smoothness)
    }
    
    # 5. æ›²é¢æ³•å‘é‡çš„ä¸€è‡´æ€§
    normals = []
    for i in range(1, grid_size - 1):
        for j in range(1, grid_size - 1):
            # è®¡ç®—å±€éƒ¨æ³•å‘é‡
            p1 = generated_points[i-1, j] - generated_points[i, j]
            p2 = generated_points[i, j-1] - generated_points[i, j]
            normal = np.cross(p1, p2)
            if np.linalg.norm(normal) > 0:
                normal = normal / np.linalg.norm(normal)
                normals.append(normal)
    
    if normals:
        normals = np.array(normals)
        # è®¡ç®—æ³•å‘é‡çš„ä¸€è‡´æ€§ï¼ˆç›¸é‚»æ³•å‘é‡çš„è§’åº¦å·®ï¼‰
        angles = []
        for i in range(len(normals) - 1):
            cos_angle = np.clip(np.dot(normals[i], normals[i+1]), -1, 1)
            angle = np.arccos(cos_angle)
            angles.append(angle)
        
        metrics['normal_consistency'] = {
            'mean_angle_diff': np.mean(angles),
            'std_angle_diff': np.std(angles)
        }
    
    return metrics

def print_analysis_report(metrics: dict):
    """æ‰“å°åˆ†ææŠ¥å‘Š"""
    print("\n" + "="*50)
    print("æ›²é¢ç”Ÿæˆè´¨é‡åˆ†ææŠ¥å‘Š")
    print("="*50)
    
    print(f"\n1. è¦†ç›–èŒƒå›´åˆ†æ:")
    print(f"   è¡€ç®¡èŒƒå›´: {metrics['vessel_bbox']['range']}")
    print(f"   æ›²é¢èŒƒå›´: {metrics['surface_bbox']['range']}")
    print(f"   è¦†ç›–æ¯”ä¾‹: {metrics['coverage_ratio']}")
    
    print(f"\n2. ä¸­å¿ƒå¯¹é½åˆ†æ:")
    print(f"   ä¸­å¿ƒè·ç¦»: {metrics['center_distance']:.4f}")
    
    print(f"\n3. æ‹Ÿåˆç²¾åº¦åˆ†æ:")
    dist_stats = metrics['min_distance_stats']
    print(f"   å¹³å‡æœ€å°è·ç¦»: {dist_stats['mean']:.4f}")
    print(f"   è·ç¦»æ ‡å‡†å·®: {dist_stats['std']:.4f}")
    print(f"   è·ç¦»ä¸­ä½æ•°: {dist_stats['median']:.4f}")
    print(f"   æœ€å¤§è·ç¦»: {dist_stats['max']:.4f}")
    
    print(f"\n4. å¹³æ»‘åº¦åˆ†æ:")
    smooth = metrics['smoothness']
    print(f"   æ°´å¹³å¹³æ»‘åº¦: {smooth['horizontal_mean']:.4f} Â± {smooth['horizontal_std']:.4f}")
    print(f"   å‚ç›´å¹³æ»‘åº¦: {smooth['vertical_mean']:.4f} Â± {smooth['vertical_std']:.4f}")
    
    if 'normal_consistency' in metrics:
        print(f"\n5. æ³•å‘é‡ä¸€è‡´æ€§:")
        normal = metrics['normal_consistency']
        print(f"   å¹³å‡è§’åº¦å·®: {normal['mean_angle_diff']:.4f} rad")
        print(f"   è§’åº¦å·®æ ‡å‡†å·®: {normal['std_angle_diff']:.4f} rad")

def comprehensive_surface_validation(tree_json: str, generated_points: np.ndarray, save_prefix: str = "surface_validation", interactive: bool = True):
    """
    ç»¼åˆæ›²é¢éªŒè¯ï¼šå¯è§†åŒ– + è´¨é‡åˆ†æ
    
    Args:
        tree_json: è¡€ç®¡æ ‘jsonæ–‡ä»¶è·¯å¾„
        generated_points: ç”Ÿæˆçš„æ›²é¢ç‚¹ï¼Œå½¢çŠ¶ä¸º(grid_size, grid_size, 3)
        save_prefix: ä¿å­˜æ–‡ä»¶çš„å‰ç¼€
        interactive: æ˜¯å¦æ˜¾ç¤ºäº¤äº’å¼3Dç•Œé¢
    """
    print("å¼€å§‹ç»¼åˆæ›²é¢éªŒè¯...")
    
    # 1. å¯è§†åŒ–
    print("1. ç”Ÿæˆå¯è§†åŒ–å›¾åƒ...")
    visualize_generated_surface(tree_json, generated_points, f"{save_prefix}_visualization.png", interactive=interactive)
    
    # 2. è´¨é‡åˆ†æ
    print("2. è¿›è¡Œè´¨é‡åˆ†æ...")
    metrics = analyze_surface_quality(tree_json, generated_points)
    
    # 3. æ‰“å°æŠ¥å‘Š
    print_analysis_report(metrics)
    
    # 4. ä¿å­˜åˆ†æç»“æœ
    import json
    
    def convert_numpy_to_serializable(obj):
        """é€’å½’è½¬æ¢numpyå¯¹è±¡ä¸ºå¯åºåˆ—åŒ–æ ¼å¼"""
        if isinstance(obj, np.ndarray):
            if obj.ndim == 0:  # æ ‡é‡
                return float(obj)
            else:  # å¤šç»´æ•°ç»„
                return obj.tolist()
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, dict):
            return {k: convert_numpy_to_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_numpy_to_serializable(item) for item in obj]
        else:
            return obj
    
    with open(f"{save_prefix}_metrics.json", 'w') as f:
        serializable_metrics = convert_numpy_to_serializable(metrics)
        json.dump(serializable_metrics, f, indent=2)
    
    print(f"\néªŒè¯å®Œæˆï¼ç»“æœå·²ä¿å­˜:")
    print(f"- å¯è§†åŒ–å›¾åƒ: {save_prefix}_visualization.png")
    print(f"- è´¨é‡æŒ‡æ ‡: {save_prefix}_metrics.json")
    
    if interactive:
        print("äº¤äº’å¼3Dç•Œé¢å·²æ˜¾ç¤ºï¼Œæ‚¨å¯ä»¥ä»å¤šä¸ªè§†è§’æŸ¥çœ‹ç”Ÿæˆçš„æ›²é¢æ•ˆæœ")
    
    return metrics

def visualize_optimal_plane(tree_json: str, grid_size=32, point_spacing=0.2, save_path: str = None, interactive: bool = True):
    """
    å¯è§†åŒ–æ‰¾åˆ°çš„æœ€ä¼˜åˆå§‹å¹³é¢å’Œåˆå§‹ç½‘æ ¼ç‚¹åˆ†å¸ƒ
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    with open(tree_json,'r') as fp:
        td=json.load(fp)
    
    # è·å–ä¸»å¹²ç‚¹å’Œåˆ†æ”¯ç‚¹
    trunk_pts, br1_pts, br2_pts = find_max_points_branches(td)
    all_branch_pts = np.vstack([br1_pts, br2_pts])
    
    # 1. è®¡ç®—æ‰€æœ‰ç‚¹çš„ä¸­å¿ƒä½œä¸ºå¹³é¢ä¸­å¿ƒ
    all_points = np.vstack([trunk_pts, br1_pts, br2_pts])
    plane_center = all_points.mean(axis=0)
    
    # 2. æ‰¾åˆ°ç»è¿‡åˆ†æ”¯æœ€å¤šçš„å¹³é¢ï¼ˆåˆ†æ”¯ç‚¹çš„ä¸»å¹³é¢ï¼‰
    branch_center = all_branch_pts.mean(axis=0)
    branch_centered = all_branch_pts - branch_center
    
    # è®¡ç®—åˆ†æ”¯ç‚¹çš„ä¸»å¹³é¢æ³•å‘é‡
    if len(branch_centered) >= 3:
        branch_cov = np.cov(branch_centered.T)
        branch_eigenvals, branch_eigenvecs = np.linalg.eigh(branch_cov)
        branch_idx = np.argsort(branch_eigenvals)[::-1]
        
        # åˆ†æ”¯ä¸»å¹³é¢ç”±å‰ä¸¤ä¸ªä¸»æˆåˆ†ç¡®å®šï¼Œæ³•å‘é‡æ˜¯ç¬¬ä¸‰ä¸ªä¸»æˆåˆ†
        branch_plane_normal = branch_eigenvecs[:, branch_idx[2]]  # æœ€å°ç‰¹å¾å€¼å¯¹åº”æ–¹å‘
    else:
        # å¦‚æœåˆ†æ”¯ç‚¹å¤ªå°‘ï¼Œä½¿ç”¨é»˜è®¤æ³•å‘é‡
        branch_plane_normal = np.array([0, 0, 1])
    
    # ç¡®ä¿æ³•å‘é‡æ˜¯å•ä½å‘é‡
    branch_plane_normal = branch_plane_normal / np.linalg.norm(branch_plane_normal)
    
    # 3. æ‰¾åˆ°ä¸åˆ†æ”¯å¹³é¢å‚ç›´ä¸”ç»è¿‡ä¸»å¹²æœ€å¤šçš„å¹³é¢
    trunk_center = trunk_pts.mean(axis=0)
    trunk_centered = trunk_pts - trunk_center
    
    # å°†ä¸»å¹²ç‚¹æŠ•å½±åˆ°å‚ç›´äºåˆ†æ”¯å¹³é¢æ³•å‘é‡çš„ç©ºé—´ä¸­
    projection_matrix = np.eye(3) - np.outer(branch_plane_normal, branch_plane_normal)
    trunk_projected = trunk_centered @ projection_matrix.T
    
    # åœ¨æŠ•å½±ç©ºé—´ä¸­æ‰¾ä¸»å¹²ç‚¹çš„ä¸»æ–¹å‘
    if len(trunk_projected) >= 2:
        trunk_proj_cov = np.cov(trunk_projected.T)
        trunk_eigenvals, trunk_eigenvecs = np.linalg.eigh(trunk_proj_cov)
        trunk_idx = np.argsort(trunk_eigenvals)[::-1]
        
        # ä¸»å¹²åœ¨æŠ•å½±ç©ºé—´ä¸­çš„ä¸»æ–¹å‘
        trunk_main_dir_projected = trunk_eigenvecs[:, trunk_idx[0]]
    else:
        trunk_main_dir_projected = np.array([1, 0, 0])
        trunk_main_dir_projected = trunk_main_dir_projected - np.dot(trunk_main_dir_projected, branch_plane_normal) * branch_plane_normal
    
    # ç¡®ä¿ä¸»å¹²ä¸»æ–¹å‘æ˜¯å•ä½å‘é‡
    trunk_main_dir_projected = trunk_main_dir_projected / (np.linalg.norm(trunk_main_dir_projected) + 1e-8)
    
    # 4. æ„å»ºåˆå§‹å¹³é¢çš„åæ ‡ç³»
    plane_normal = branch_plane_normal
    u_axis = trunk_main_dir_projected
    v_axis = np.cross(plane_normal, u_axis)
    v_axis = v_axis / (np.linalg.norm(v_axis) + 1e-8)
    u_axis = np.cross(v_axis, plane_normal)
    u_axis = u_axis / (np.linalg.norm(u_axis) + 1e-8)
    
    # 5. åœ¨å¹³é¢ä¸Šç”Ÿæˆ32x32çš„æ­£æ–¹å½¢ç½‘æ ¼ï¼Œé—´éš”ä¸ºpoint_spacing
    grid_extent = (grid_size - 1) * point_spacing / 2
    u_coords = np.linspace(-grid_extent, grid_extent, grid_size)
    v_coords = np.linspace(-grid_extent, grid_extent, grid_size)
    U, V = np.meshgrid(u_coords, v_coords)
    
    # å°†ç½‘æ ¼ç‚¹è½¬æ¢åˆ°3Dç©ºé—´
    grid_points = []
    for i in range(grid_size):
        for j in range(grid_size):
            point_3d = plane_center + U[i,j] * u_axis + V[i,j] * v_axis
            grid_points.append(point_3d)
    
    grid_points = np.array(grid_points)
    
    # æ„å»ºåˆ†æ”¯å¹³é¢çš„åæ ‡ç³»ç”¨äºå¯è§†åŒ–
    if abs(np.dot(branch_plane_normal, np.array([1, 0, 0]))) < 0.9:
        branch_u = np.cross(branch_plane_normal, np.array([1, 0, 0]))
    else:
        branch_u = np.cross(branch_plane_normal, np.array([0, 1, 0]))
    branch_u = branch_u / np.linalg.norm(branch_u)
    branch_v = np.cross(branch_plane_normal, branch_u)
    branch_v = branch_v / np.linalg.norm(branch_v)
    
    # å¯è§†åŒ–
    fig = plt.figure(figsize=(20, 6))
    
    # å­å›¾1: åˆ†æ”¯ä¸»å¹³é¢åˆ†æ
    ax1 = fig.add_subplot(141, projection='3d')
    ax1.scatter(*trunk_pts.T, c='blue', s=3, alpha=0.8, label='ä¸»å¹²')
    ax1.scatter(*br1_pts.T, c='green', s=3, alpha=0.8, label='åˆ†æ”¯1')
    ax1.scatter(*br2_pts.T, c='red', s=3, alpha=0.8, label='åˆ†æ”¯2')
    
    # ç»˜åˆ¶åˆ†æ”¯ä¸»å¹³é¢
    plane_size = grid_extent * 1.5
    plane_u = np.linspace(-plane_size, plane_size, 20)
    plane_v = np.linspace(-plane_size, plane_size, 20)
    Plane_U, Plane_V = np.meshgrid(plane_u, plane_v)
    
    branch_plane_points = np.zeros((20, 20, 3))
    for i in range(20):
        for j in range(20):
            branch_plane_points[i, j] = branch_center + Plane_U[i,j] * branch_u + Plane_V[i,j] * branch_v
    
    ax1.plot_surface(branch_plane_points[:,:,0], branch_plane_points[:,:,1], branch_plane_points[:,:,2], 
                    alpha=0.3, color='cyan')
    ax1.set_title('åˆ†æ”¯ä¸»å¹³é¢\n(ç»è¿‡åˆ†æ”¯æœ€å¤šçš„å¹³é¢)')
    ax1.legend()
    ax1.set_axis_off()
    
    # å­å›¾2: åˆå§‹å¹³é¢ä½ç½®
    ax2 = fig.add_subplot(142, projection='3d')
    ax2.scatter(*trunk_pts.T, c='blue', s=3, alpha=0.8, label='ä¸»å¹²')
    ax2.scatter(*br1_pts.T, c='green', s=3, alpha=0.8, label='åˆ†æ”¯1')
    ax2.scatter(*br2_pts.T, c='red', s=3, alpha=0.8, label='åˆ†æ”¯2')
    
    # ç»˜åˆ¶åˆå§‹å¹³é¢
    initial_plane_points = np.zeros((20, 20, 3))
    for i in range(20):
        for j in range(20):
            initial_plane_points[i, j] = plane_center + Plane_U[i,j] * u_axis + Plane_V[i,j] * v_axis
    
    ax2.plot_surface(initial_plane_points[:,:,0], initial_plane_points[:,:,1], initial_plane_points[:,:,2], 
                    alpha=0.4, color='yellow')
    
    # ç»˜åˆ¶åˆ†æ”¯å¹³é¢ï¼ˆåŠé€æ˜å¯¹æ¯”ï¼‰
    ax2.plot_surface(branch_plane_points[:,:,0], branch_plane_points[:,:,1], branch_plane_points[:,:,2], 
                    alpha=0.1, color='cyan')
    
    ax2.set_title('åˆå§‹å¹³é¢\n(ä¸åˆ†æ”¯å¹³é¢å‚ç›´ï¼Œç»è¿‡ä¸»å¹²æœ€å¤š)')
    ax2.legend()
    ax2.set_axis_off()
    
    # å­å›¾3: åˆå§‹ç½‘æ ¼ç‚¹
    ax3 = fig.add_subplot(143, projection='3d')
    ax3.scatter(*trunk_pts.T, c='blue', s=2, alpha=0.5, label='ä¸»å¹²')
    ax3.scatter(*br1_pts.T, c='green', s=2, alpha=0.5, label='åˆ†æ”¯1')
    ax3.scatter(*br2_pts.T, c='red', s=2, alpha=0.5, label='åˆ†æ”¯2')
    ax3.scatter(*grid_points.T, c='orange', s=5, alpha=0.8, label='åˆå§‹ç½‘æ ¼ç‚¹')
    
    # ç»˜åˆ¶ç½‘æ ¼çº¿
    grid_reshaped = grid_points.reshape(grid_size, grid_size, 3)
    for i in range(0, grid_size, 4):
        line_points = grid_reshaped[i, :, :]
        ax3.plot(line_points[:, 0], line_points[:, 1], line_points[:, 2], 
               color='red', alpha=0.7, linewidth=1)
    for j in range(0, grid_size, 4):
        line_points = grid_reshaped[:, j, :]
        ax3.plot(line_points[:, 0], line_points[:, 1], line_points[:, 2], 
               color='red', alpha=0.7, linewidth=1)
    
    ax3.set_title(f'åˆå§‹ç½‘æ ¼: {grid_size}Ã—{grid_size}\né—´è·: {point_spacing}')
    ax3.legend()
    ax3.set_axis_off()
    
    # å­å›¾4: å¹³é¢è§†å›¾ï¼ˆä»åˆ†æ”¯å¹³é¢æ³•å‘é‡æ–¹å‘çœ‹ï¼‰
    ax4 = fig.add_subplot(144)
    
    # å°†æ‰€æœ‰ç‚¹æŠ•å½±åˆ°åˆå§‹å¹³é¢ä¸Š
    trunk_proj = np.array([np.dot(pt - plane_center, u_axis) for pt in trunk_pts]), \
                 np.array([np.dot(pt - plane_center, v_axis) for pt in trunk_pts])
    br1_proj = np.array([np.dot(pt - plane_center, u_axis) for pt in br1_pts]), \
               np.array([np.dot(pt - plane_center, v_axis) for pt in br1_pts])
    br2_proj = np.array([np.dot(pt - plane_center, u_axis) for pt in br2_pts]), \
               np.array([np.dot(pt - plane_center, v_axis) for pt in br2_pts])
    
    ax4.scatter(*trunk_proj, c='blue', s=3, alpha=0.6, label='ä¸»å¹²æŠ•å½±')
    ax4.scatter(*br1_proj, c='green', s=3, alpha=0.6, label='åˆ†æ”¯1æŠ•å½±')
    ax4.scatter(*br2_proj, c='red', s=3, alpha=0.6, label='åˆ†æ”¯2æŠ•å½±')
    ax4.scatter(U.flatten(), V.flatten(), c='orange', s=8, alpha=0.8, label='ç½‘æ ¼ç‚¹')
    
    # ç»˜åˆ¶ç½‘æ ¼çº¿
    for i in range(0, grid_size, 4):
        ax4.plot(U[i, :], V[i, :], color='red', alpha=0.5, linewidth=1)
    for j in range(0, grid_size, 4):
        ax4.plot(U[:, j], V[:, j], color='red', alpha=0.5, linewidth=1)
    
    ax4.set_title('åˆå§‹å¹³é¢è§†å›¾')
    ax4.set_xlabel('Uè½´ï¼ˆä¸»å¹²ä¸»æ–¹å‘ï¼‰')
    ax4.set_ylabel('Vè½´')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    ax4.set_aspect('equal')
    
    # ç»Ÿä¸€è®¾ç½®3Dè§†å›¾èŒƒå›´
    all_points_vis = np.vstack([trunk_pts, br1_pts, br2_pts, grid_points])
    center = all_points_vis.mean(axis=0)
    range_val = 30
    
    for ax in [ax1, ax2, ax3]:
        ax.set_xlim(center[0] - range_val, center[0] + range_val)
        ax.set_ylim(center[1] - range_val, center[1] + range_val)
        ax.set_zlim(center[2] - range_val, center[2] + range_val)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"åˆå§‹å¹³é¢å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")
    
    # æ˜¾ç¤ºäº¤äº’å¼ç•Œé¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if interactive:
        print("æ­£åœ¨æ‰“å¼€åˆå§‹å¹³é¢åˆ†æçš„äº¤äº’å¼3Dç•Œé¢...")
        print("æ‚¨å¯ä»¥ä»å¤šä¸ªè§†è§’æŸ¥çœ‹åˆå§‹å¹³é¢çš„æ„å»ºè¿‡ç¨‹")
        plt.show()
    else:
        plt.close()
    
    print(f"åˆå§‹å¹³é¢ä¿¡æ¯:")
    print(f"  å¹³é¢ä¸­å¿ƒ: {plane_center}")
    print(f"  åˆ†æ”¯å¹³é¢æ³•å‘é‡: {branch_plane_normal}")
    print(f"  ä¸»å¹²ä¸»æ–¹å‘ï¼ˆæŠ•å½±åï¼‰: {trunk_main_dir_projected}")
    print(f"  åˆå§‹å¹³é¢æ³•å‘é‡: {plane_normal}")
    print(f"  ç½‘æ ¼å°ºå¯¸: {grid_extent*2:.2f} Ã— {grid_extent*2:.2f}")
    print(f"  ç‚¹é—´è·: {point_spacing}")
    
    # éªŒè¯å‚ç›´æ€§
    dot_product = np.dot(plane_normal, branch_plane_normal)
    print(f"  å¹³é¢å‚ç›´æ€§éªŒè¯: {abs(dot_product):.6f} (æ¥è¿‘0è¡¨ç¤ºå‚ç›´)")
    
    return plane_center, plane_normal, u_axis, v_axis, grid_points

def visualize_training_target_surface(tree_json: str, grid_size=32, point_spacing=0.2, save_path: str = None, interactive: bool = True):
    """
    å¯è§†åŒ–è®­ç»ƒç›®æ ‡æ›²é¢ï¼ˆä»¥ä¸­è½´çº¿ä¸ºéª¨æ¶çš„æ›²é¢ï¼‰
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    with open(tree_json,'r') as fp:
        td=json.load(fp)
    
    # è·å–ä¸»å¹²å’Œåˆ†æ”¯ç‚¹
    trunk_pts, br1_pts, br2_pts = find_max_points_branches(td)
    
    # è®¡ç®—ä¸¤ä¸ªåˆ†æ”¯å¯¹åº”ç‚¹çš„ä¸­ç‚¹ï¼Œæ„å»ºä¸­è½´çº¿
    min_len = min(len(br1_pts), len(br2_pts))
    if min_len > 0:
        br1_sampled = br1_pts[:min_len]
        br2_sampled = br2_pts[:min_len]
        midpoints = (br1_sampled + br2_sampled) / 2.0
    else:
        midpoints = np.array([trunk_pts[-1]])
    
    # æ„å»ºä¸­è½´çº¿ï¼šä¸»å¹²ç‚¹ + åˆ†æ”¯ä¸­ç‚¹
    centerline_points = np.vstack([trunk_pts, midpoints])
    
    # å¯¹ä¸­è½´çº¿ç‚¹è¿›è¡Œæ’åºï¼Œç¡®ä¿è¿ç»­æ€§
    centerline_center = centerline_points.mean(axis=0)
    centerline_centered = centerline_points - centerline_center
    
    # ä½¿ç”¨PCAæ‰¾åˆ°ä¸­è½´çº¿çš„ä¸»æ–¹å‘
    cov_matrix = np.cov(centerline_centered.T)
    eigenvals, eigenvecs = np.linalg.eig(cov_matrix)
    idx = np.argsort(eigenvals)[::-1]
    main_direction = eigenvecs[:, idx[0]]  # ä¸­è½´çº¿ä¸»æ–¹å‘
    
    # å°†ä¸­è½´çº¿ç‚¹æŠ•å½±åˆ°ä¸»æ–¹å‘ä¸Šå¹¶æ’åº
    projections = np.dot(centerline_centered, main_direction)
    sorted_indices = np.argsort(projections)
    sorted_centerline = centerline_points[sorted_indices]
    
    
    
    # ç”Ÿæˆè®­ç»ƒç›®æ ‡æ›²é¢
    temp_dataset = TempDataset()
    target_surface = temp_dataset._generate_surface_grid(
        sorted_centerline, main_direction, grid_size, point_spacing
    )
    
    # å¯è§†åŒ–
    fig = plt.figure(figsize=(20, 6))
    
    # å­å›¾1: ä¸­è½´çº¿å’Œè¡€ç®¡ç‚¹
    ax1 = fig.add_subplot(141, projection='3d')
    ax1.scatter(*trunk_pts.T, c='blue', s=3, alpha=0.8, label='ä¸»å¹²')
    ax1.scatter(*br1_pts.T, c='green', s=3, alpha=0.8, label='åˆ†æ”¯1')
    ax1.scatter(*br2_pts.T, c='red', s=3, alpha=0.8, label='åˆ†æ”¯2')
    ax1.scatter(*midpoints.T, c='purple', s=5, alpha=0.9, label='åˆ†æ”¯ä¸­ç‚¹')
    ax1.plot(*sorted_centerline.T, 'orange', linewidth=3, alpha=0.8, label='ä¸­è½´çº¿')
    ax1.set_title('ä¸­è½´çº¿æ„å»º')
    ax1.legend()
    ax1.set_axis_off()
    
    # å­å›¾2: ç›®æ ‡æ›²é¢
    ax2 = fig.add_subplot(142, projection='3d')
    X, Y, Z = target_surface[:, :, 0], target_surface[:, :, 1], target_surface[:, :, 2]
    ax2.plot_surface(X, Y, Z, alpha=0.7, cmap='viridis')
    ax2.plot(*sorted_centerline.T, 'red', linewidth=3, alpha=1.0, label='ä¸­è½´çº¿')
    ax2.set_title('è®­ç»ƒç›®æ ‡æ›²é¢')
    ax2.legend()
    ax2.set_axis_off()
    
    # å­å›¾3: æ›²é¢+è¡€ç®¡å åŠ 
    ax3 = fig.add_subplot(143, projection='3d')
    ax3.scatter(*trunk_pts.T, c='blue', s=2, alpha=0.6, label='ä¸»å¹²')
    ax3.scatter(*br1_pts.T, c='green', s=2, alpha=0.6, label='åˆ†æ”¯1')
    ax3.scatter(*br2_pts.T, c='red', s=2, alpha=0.6, label='åˆ†æ”¯2')
    ax3.plot_surface(X, Y, Z, alpha=0.4, color='orange')
    ax3.plot(*sorted_centerline.T, 'purple', linewidth=2, alpha=0.8)
    
    # ç»˜åˆ¶ç½‘æ ¼çº¿æ˜¾ç¤ºç»“æ„
    for i in range(0, grid_size, 4):
        ax3.plot(X[i, :], Y[i, :], Z[i, :], 'k-', alpha=0.3, linewidth=0.5)
    for j in range(0, grid_size, 4):
        ax3.plot(X[:, j], Y[:, j], Z[:, j], 'k-', alpha=0.3, linewidth=0.5)
    
    ax3.set_title('æ›²é¢ä¸è¡€ç®¡å åŠ ')
    ax3.legend()
    ax3.set_axis_off()
    
    # å­å›¾4: ç½‘æ ¼ç‚¹åˆ†å¸ƒ
    ax4 = fig.add_subplot(144, projection='3d')
    surface_points_flat = target_surface.reshape(-1, 3)
    ax4.scatter(*surface_points_flat.T, c='orange', s=2, alpha=0.8, label='æ›²é¢ç½‘æ ¼ç‚¹')
    ax4.plot(*sorted_centerline.T, 'red', linewidth=2, alpha=0.8, label='ä¸­è½´çº¿')
    
    # æ˜¾ç¤ºç½‘æ ¼ç»“æ„
    for i in range(0, grid_size, 2):
        line_points = target_surface[i, :, :]
        ax4.plot(line_points[:, 0], line_points[:, 1], line_points[:, 2], 
               'b-', alpha=0.5, linewidth=0.5)
    for j in range(0, grid_size, 2):
        line_points = target_surface[:, j, :]
        ax4.plot(line_points[:, 0], line_points[:, 1], line_points[:, 2], 
               'g-', alpha=0.5, linewidth=0.5)
    
    ax4.set_title(f'ç½‘æ ¼ç‚¹åˆ†å¸ƒ\n{grid_size}Ã—{grid_size}, é—´è·{point_spacing}')
    ax4.legend()
    ax4.set_axis_off()
    
    # ç»Ÿä¸€è®¾ç½®è§†å›¾èŒƒå›´
    all_points = np.vstack([trunk_pts, br1_pts, br2_pts, surface_points_flat])
    center = all_points.mean(axis=0)
    range_val = 30
    
    for ax in [ax1, ax2, ax3, ax4]:
        ax.set_xlim(center[0] - range_val, center[0] + range_val)
        ax.set_ylim(center[1] - range_val, center[1] + range_val)
        ax.set_zlim(center[2] - range_val, center[2] + range_val)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"è®­ç»ƒç›®æ ‡æ›²é¢å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")
    
    # æ˜¾ç¤ºäº¤äº’å¼ç•Œé¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if interactive:
        print("æ­£åœ¨æ‰“å¼€è®­ç»ƒç›®æ ‡æ›²é¢çš„äº¤äº’å¼3Dç•Œé¢...")
        print("æ‚¨å¯ä»¥ä»å¤šä¸ªè§†è§’æŸ¥çœ‹è®­ç»ƒç›®æ ‡æ›²é¢çš„æ„å»ºè¿‡ç¨‹")
        plt.show()
    else:
        plt.close()
    
    print(f"è®­ç»ƒç›®æ ‡æ›²é¢ä¿¡æ¯:")
    print(f"  ä¸­è½´çº¿ç‚¹æ•°: {len(sorted_centerline)}")
    print(f"  æ›²é¢ç½‘æ ¼: {grid_size}Ã—{grid_size}")
    print(f"  ç‚¹é—´è·: {point_spacing}")
    print(f"  æ›²é¢èŒƒå›´: {(grid_size-1)*point_spacing:.2f}")
    print(f"  æ€»ç‚¹æ•°: {grid_size*grid_size}")
    
    return target_surface, sorted_centerline

# --------- å¿«é€Ÿæ¼”ç¤ºäº¤äº’å¼å¯è§†åŒ– ---------

def quick_demo_interactive_visualization(tree_json: str):
    """
    å¿«é€Ÿæ¼”ç¤ºäº¤äº’å¼3Då¯è§†åŒ–åŠŸèƒ½
    """
    print("=== äº¤äº’å¼3Då¯è§†åŒ–æ¼”ç¤º ===")
    print("å³å°†ä¾æ¬¡å±•ç¤º4ä¸ªäº¤äº’å¼3Dç•Œé¢ï¼Œæ‚¨å¯ä»¥:")
    print("- ç”¨é¼ æ ‡æ‹–æ‹½æ—‹è½¬è§†è§’")
    print("- ç”¨æ»šè½®ç¼©æ”¾")
    print("- å…³é—­å½“å‰çª—å£æŸ¥çœ‹ä¸‹ä¸€ä¸ªç•Œé¢")
    print("- æŒ‰Ctrl+Cä¸­æ–­æ¼”ç¤º")
    
    input("æŒ‰å›è½¦é”®å¼€å§‹æ¼”ç¤º...")
    
    try:
        # 1. å±•ç¤ºæœ€ä¼˜åˆå§‹å¹³é¢
        print("\n1. æœ€ä¼˜åˆå§‹å¹³é¢åˆ†æ")
        # visualize_optimal_plane(tree_json, grid_size=16, point_spacing=0.3, 
        #                        save_path=None, interactive=True)
        
        # 2. å±•ç¤ºè®­ç»ƒç›®æ ‡æ›²é¢  
        print("\n2. è®­ç»ƒç›®æ ‡æ›²é¢")
        target_surface, _ = visualize_training_target_surface(
            tree_json, grid_size=16, point_spacing=0.3,
            save_path=None, interactive=True
        )
        
        # 3. å¦‚æœæœ‰è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå±•ç¤ºç”Ÿæˆç»“æœ
        print("\n3. åŸºäºä¸­è½´çº¿çš„åˆ†éš”æ›²é¢")
        print("æ³¨æ„ï¼šæ­¤æ¼”ç¤ºä½¿ç”¨åŸºäºä¸­è½´çº¿çš„æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦è®­ç»ƒå¥½çš„æ¨¡å‹")
        
        # è¯»å–è¡€ç®¡æ ‘æ•°æ®å¹¶è®¡ç®—ä¸­è½´çº¿
        with open(tree_json, 'r') as fp:
            td = json.load(fp)
        
        trunk_pts, br1_pts, br2_pts = safe_find_max_points_branches(td)
        
        # è®¡ç®—åˆ†æ”¯ä¸­ç‚¹æ„å»ºä¸­è½´çº¿
        min_len = min(len(br1_pts), len(br2_pts))
        if min_len > 0:
            br1_sampled = br1_pts[:min_len]
            br2_sampled = br2_pts[:min_len]
            midpoints = (br1_sampled + br2_sampled) / 2.0
        else:
            midpoints = np.array([trunk_pts[-1]])
        
        # æ„å»ºä¸­è½´çº¿ï¼šä¸»å¹²ç‚¹ + åˆ†æ”¯ä¸­ç‚¹
        centerline_points = np.vstack([trunk_pts, midpoints])
        centerline_center = centerline_points.mean(axis=0)
        centerline_centered = centerline_points - centerline_center
        
        # ä½¿ç”¨PCAæ‰¾åˆ°ä¸­è½´çº¿çš„ä¸»æ–¹å‘
        cov_matrix = np.cov(centerline_centered.T)
        eigenvals, eigenvecs = np.linalg.eig(cov_matrix)
        idx = np.argsort(eigenvals)[::-1]
        main_direction = eigenvecs[:, idx[0]]  # ä¸­è½´çº¿ä¸»æ–¹å‘
        
        # å°†ä¸­è½´çº¿ç‚¹æŠ•å½±åˆ°ä¸»æ–¹å‘ä¸Šå¹¶æ’åº
        projections = np.dot(centerline_centered, main_direction)
        sorted_indices = np.argsort(projections)
        sorted_centerline = centerline_points[sorted_indices]
        
        print(f"ä¸­è½´çº¿ä¿¡æ¯: {len(sorted_centerline)} ä¸ªç‚¹ï¼Œä¸»æ–¹å‘: {main_direction}")
        
        # åˆ›å»ºåŸºäºä¸­è½´çº¿çš„åˆ†éš”æ›²é¢ï¼Œæœ‰æ•ˆåˆ†ç¦»ä¸¤ä¸ªåˆ†æ”¯
        grid_size = 16
        demo_surface = np.zeros((grid_size, grid_size, 3))
        
        # åˆ†æä¸¤ä¸ªåˆ†æ”¯çš„åˆ†å¸ƒ
        br1_center = br1_pts.mean(axis=0)
        br2_center = br2_pts.mean(axis=0)
        centerline_center = sorted_centerline.mean(axis=0)
        
        # æ–¹æ³•ï¼šä½¿ç”¨ä¸¤ä¸ªåˆ†æ”¯ä¸­å¿ƒè¿çº¿çš„å‚ç›´å¹³åˆ†é¢ä½œä¸ºåˆ†éš”åŸºå‡†
        branch_connection = br2_center - br1_center  # ä»åˆ†æ”¯1æŒ‡å‘åˆ†æ”¯2çš„å‘é‡
        branch_midpoint = (br1_center + br2_center) / 2  # ä¸¤åˆ†æ”¯çš„ä¸­ç‚¹
        
        # åˆ†éš”é¢æ³•å‘é‡ï¼šä¸¤ä¸ªåˆ†æ”¯ä¸­å¿ƒçš„è¿çº¿æ–¹å‘
        if np.linalg.norm(branch_connection) > 1e-6:
            separation_normal = branch_connection / np.linalg.norm(branch_connection)
        else:
            # å¦‚æœä¸¤ä¸ªåˆ†æ”¯ä¸­å¿ƒé‡åˆï¼Œä½¿ç”¨åˆ†æ”¯ç‚¹çš„ä¸»æˆåˆ†åˆ†æ
            all_branch_pts = np.vstack([br1_pts, br2_pts])
            branch_centered = all_branch_pts - all_branch_pts.mean(axis=0)
            if len(branch_centered) >= 3:
                branch_cov = np.cov(branch_centered.T)
                eigenvals, eigenvecs = np.linalg.eigh(branch_cov)
                idx = np.argsort(eigenvals)[::-1]
                separation_normal = eigenvecs[:, idx[0]]  # æœ€å¤§å˜åŒ–æ–¹å‘
            else:
                separation_normal = np.array([1, 0, 0])
        
        # æ„å»ºåˆ†éš”æ›²é¢çš„åæ ‡ç³»
        # uè½´ï¼šä¸­è½´çº¿ä¸»æ–¹å‘åœ¨åˆ†éš”é¢ä¸Šçš„æŠ•å½±ï¼ˆæ²¿è¡€ç®¡èµ°å‘ï¼‰
        centerline_proj = main_direction - np.dot(main_direction, separation_normal) * separation_normal
        if np.linalg.norm(centerline_proj) < 1e-6:
            # å¦‚æœä¸­è½´çº¿ä¸åˆ†éš”é¢æ³•å‘é‡å¹³è¡Œï¼Œé€‰æ‹©å…¶ä»–æ–¹å‘
            temp_vec = np.array([0, 0, 1]) if abs(separation_normal[2]) < 0.9 else np.array([1, 0, 0])
            centerline_proj = temp_vec - np.dot(temp_vec, separation_normal) * separation_normal
        
        u_axis = centerline_proj / np.linalg.norm(centerline_proj)
        
        # vè½´ï¼šå‚ç›´äºuè½´å’Œæ³•å‘é‡
        v_axis = np.cross(separation_normal, u_axis)
        v_axis = v_axis / np.linalg.norm(v_axis)
        
        # éªŒè¯åˆ†ç¦»æ•ˆæœ
        br1_to_midpoint = br1_center - branch_midpoint
        br2_to_midpoint = br2_center - branch_midpoint
        br1_side = np.dot(br1_to_midpoint, separation_normal)
        br2_side = np.dot(br2_to_midpoint, separation_normal)
        
        print(f"åˆ†æ”¯åˆ†ç¦»åˆ†æ:")
        print(f"  åˆ†æ”¯1ä¸­å¿ƒ: {br1_center}")
        print(f"  åˆ†æ”¯2ä¸­å¿ƒ: {br2_center}")
        print(f"  åˆ†æ”¯ä¸­ç‚¹: {branch_midpoint}")
        print(f"  åˆ†æ”¯è¿çº¿å‘é‡: {branch_connection}")
        print(f"  åˆ†éš”é¢æ³•å‘é‡: {separation_normal}")
        print(f"  åˆ†æ”¯1åˆ°åˆ†éš”é¢è·ç¦»: {br1_side:.3f}")
        print(f"  åˆ†æ”¯2åˆ°åˆ†éš”é¢è·ç¦»: {br2_side:.3f}")
        print(f"  åˆ†æ”¯æ˜¯å¦åœ¨ä¸¤ä¾§: {br1_side * br2_side < 0}")
        
        # ç¡®ä¿åˆ†éš”é¢ç»è¿‡ä¸­è½´çº¿é™„è¿‘
        # å°†åˆ†éš”é¢ä¸­å¿ƒè®¾ç½®ä¸ºä¸­è½´çº¿ä¸­å¿ƒå’Œåˆ†æ”¯ä¸­ç‚¹çš„åŠ æƒå¹³å‡
        separation_center = 0.7 * centerline_center + 0.3 * branch_midpoint
        
        # è®¡ç®—æ›²é¢å°ºå¯¸
        centerline_length = np.linalg.norm(sorted_centerline[-1] - sorted_centerline[0])
        branch_separation = np.linalg.norm(branch_connection)
        all_points = np.vstack([trunk_pts, br1_pts, br2_pts])
        points_range = np.max(all_points, axis=0) - np.min(all_points, axis=0)
        
        # uæ–¹å‘ï¼šæ²¿è¡€ç®¡èµ°å‘ï¼Œè¦†ç›–æ•´ä¸ªä¸­è½´çº¿
        surface_extent_u = max(centerline_length * 1.5, points_range.max() * 1.0)
        # væ–¹å‘ï¼šå‚ç›´æ–¹å‘ï¼Œè¶³å¤Ÿè¦†ç›–åˆ†æ”¯èŒƒå›´
        surface_extent_v = max(branch_separation * 2.0, points_range.max() * 0.8)
        
        print(f"  åˆ†éš”é¢ä¸­å¿ƒ: {separation_center}")
        print(f"  æ›²é¢å°ºå¯¸: u={surface_extent_u:.2f}, v={surface_extent_v:.2f}")
        
        # ç”Ÿæˆåˆ†éš”æ›²é¢ç‚¹
        for i in range(grid_size):
            for j in range(grid_size):
                # å‚æ•°åŒ–
                u_param = (i / (grid_size - 1) - 0.5) * 2  # -1 åˆ° 1
                v_param = (j / (grid_size - 1) - 0.5) * 2  # -1 åˆ° 1
                
                # åœ¨åˆ†éš”é¢ä¸Šç”Ÿæˆç‚¹
                offset_u = u_param * surface_extent_u * 0.4
                offset_v = v_param * surface_extent_v * 0.4
                
                # åŸºå‡†ä½ç½®ï¼šåˆ†éš”é¢ä¸­å¿ƒ
                base_point = separation_center
                
                # å¦‚æœè¦è®©æ›²é¢æ›´è´´åˆä¸­è½´çº¿ï¼Œå¯ä»¥åœ¨uæ–¹å‘ä¸Šæ’å€¼åˆ°ä¸­è½´çº¿
                if len(sorted_centerline) > 1:
                    # å°†uå‚æ•°æ˜ å°„åˆ°ä¸­è½´çº¿
                    centerline_param = (u_param + 1) / 2  # è½¬æ¢åˆ°0-1
                    centerline_param = np.clip(centerline_param, 0, 1)
                    
                    if centerline_param <= 0:
                        centerline_point = sorted_centerline[0]
                    elif centerline_param >= 1:
                        centerline_point = sorted_centerline[-1]
                    else:
                        idx_float = centerline_param * (len(sorted_centerline) - 1)
                        idx_low = int(idx_float)
                        idx_high = min(idx_low + 1, len(sorted_centerline) - 1)
                        alpha = idx_float - idx_low
                        centerline_point = (1 - alpha) * sorted_centerline[idx_low] + alpha * sorted_centerline[idx_high]
                    
                    # å°†åŸºå‡†ç‚¹è°ƒæ•´ä¸ºä¸­è½´çº¿ç‚¹åœ¨åˆ†éš”é¢ä¸Šçš„æŠ•å½±
                    centerline_to_center = centerline_point - separation_center
                    # å°†ä¸­è½´çº¿ç‚¹æŠ•å½±åˆ°åˆ†éš”é¢ä¸Š
                    projected_offset = centerline_to_center - np.dot(centerline_to_center, separation_normal) * separation_normal
                    base_point = separation_center + projected_offset * 0.8  # éƒ¨åˆ†è·Ÿéšä¸­è½´çº¿
                
                # æ·»åŠ è½»å¾®çš„æ›²é¢å¼¯æ›²ï¼Œä½¿å…¶æ›´è‡ªç„¶
                curvature = 0.1 * np.sin(u_param * np.pi) * np.cos(v_param * np.pi * 2)
                
                # è®¡ç®—æœ€ç»ˆä½ç½®
                point_3d = (base_point + 
                           offset_u * u_axis + 
                           offset_v * v_axis + 
                           curvature * separation_normal)
                
                demo_surface[i, j] = point_3d
        
        print(f"åˆ†éš”æ›²é¢ä¿¡æ¯:")
        print(f"  æ›²é¢ä¸­å¿ƒ: {demo_surface.mean(axis=(0,1))}")
        print(f"  uè½´(æ²¿è¡€ç®¡): {u_axis}")
        print(f"  vè½´(å‚ç›´): {v_axis}")
        print(f"  æ³•å‘é‡(åˆ†ç¦»æ–¹å‘): {separation_normal}")
        print(f"  ç›®æ ‡ï¼šå°†ç»¿è‰²å’Œçº¢è‰²åˆ†æ”¯åˆ†ç¦»åˆ°æ›²é¢ä¸¤ä¾§")
        
        visualize_generated_surface(tree_json, demo_surface, 
                                  save_path=None, interactive=True)
        
        # 4. è¯¦ç»†éªŒè¯åˆ†ç¦»æ•ˆæœ
        print("\n4. åˆ†ç¦»æ•ˆæœè¯¦ç»†éªŒè¯")
        print("æ˜¾ç¤ºè¯¦ç»†çš„åˆ†ç¦»æ•ˆæœåˆ†æï¼ŒåŒ…æ‹¬ç»Ÿè®¡æ•°æ®å’Œå¯è§†åŒ–")
        visualize_separation_effect(tree_json, demo_surface, interactive=True)
        
        print("\næ¼”ç¤ºå®Œæˆï¼")
        print("æ‚¨å·²ç»æŸ¥çœ‹äº†4ä¸ªäº¤äº’å¼3Dç•Œé¢:")
        print("1. æœ€ä¼˜åˆå§‹å¹³é¢åˆ†æ - æ˜¾ç¤ºå¦‚ä½•é€‰æ‹©åˆå§‹å¹³é¢")
        print("2. è®­ç»ƒç›®æ ‡æ›²é¢ - æ˜¾ç¤ºä»¥ä¸­è½´çº¿ä¸ºéª¨æ¶çš„ç›®æ ‡æ›²é¢") 
        print("3. åŸºäºä¸­è½´çº¿çš„åˆ†éš”æ›²é¢ - æ˜¾ç¤ºç”¨äºåˆ†ç¦»åˆ†æ”¯çš„æ›²é¢")
        print("4. åˆ†ç¦»æ•ˆæœè¯¦ç»†éªŒè¯ - æ˜¾ç¤ºåˆ†ç¦»æ•ˆæœçš„å®šé‡åˆ†æ")
        print("æ‰€æœ‰ç•Œé¢éƒ½æ”¯æŒäº¤äº’å¼3DæŸ¥çœ‹ï¼Œä¾¿äºä»å¤šè§’åº¦ç†è§£ç®—æ³•åŸç†ã€‚")
        
    except KeyboardInterrupt:
        print("\næ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\næ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")

if __name__=='__main__':
    import glob
    files = glob.glob('tree_*.json')
    if len(files):
        print(f"å‘ç° {len(files)} ä¸ªè¡€ç®¡æ ‘æ–‡ä»¶")
        
        # æ·»åŠ å¿«é€Ÿæ¼”ç¤ºé€‰é¡¹
        print("\né€‰æ‹©è¿è¡Œæ¨¡å¼:")
        print("1. å¿«é€Ÿäº¤äº’å¼3Då¯è§†åŒ–æ¼”ç¤º")
        print("   - æ— éœ€è®­ç»ƒï¼Œç«‹å³æŸ¥çœ‹4ä¸ªäº¤äº’å¼3Dç•Œé¢")
        print("   - åŒ…å«ï¼šåˆå§‹å¹³é¢åˆ†æã€ç›®æ ‡æ›²é¢ã€åˆ†éš”æ›²é¢ã€åˆ†ç¦»æ•ˆæœéªŒè¯")
        print("   - æ¨èç”¨äºç†è§£ç®—æ³•åŸç†å’Œè°ƒè¯•")
        print("2. å®Œæ•´è®­ç»ƒå’Œç”Ÿæˆæµç¨‹")
        print("   - åŒ…å«å®Œæ•´çš„è®­ç»ƒè¿‡ç¨‹ï¼ˆè®­ç»ƒè½®æ•°å·²è°ƒæ•´ä¸º500è½®ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•ï¼‰")
        print("   - æœ€ç»ˆä¼šæ˜¾ç¤ºå®é™…è®­ç»ƒçš„ç»“æœ")
        
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2ï¼Œé»˜è®¤ä¸º 2): ").strip()
        
        if choice == "1":
            print("å¯åŠ¨å¿«é€Ÿæ¼”ç¤ºæ¨¡å¼...")
            quick_demo_interactive_visualization(files[0])
            exit()
        else:
            print("å¯åŠ¨å®Œæ•´è®­ç»ƒæµç¨‹...")
        
        grid_size = 32
        point_spacing = 0.2  # å¯è°ƒèŠ‚çš„ç‚¹é—´è·
        
        print("=== å¯è§†åŒ–æœ€ä¼˜åˆå§‹å¹³é¢ ===")
        # visualize_optimal_plane(files[0], grid_size=grid_size, point_spacing=point_spacing, 
        #                        save_path="optimal_plane_visualization.png", interactive=True)
        
        print("\n=== å¯è§†åŒ–è®­ç»ƒç›®æ ‡æ›²é¢ ===")
        target_surface, centerline = visualize_training_target_surface(
            files[0], grid_size=grid_size, point_spacing=point_spacing, 
            save_path="training_target_surface.png", interactive=True
        )
        
        print("\n=== å¼€å§‹è®­ç»ƒæ‰©æ•£æ¨¡å‹ ===")
        model, betas = train_tree_diffusion(files, epochs=100000, device='cpu', grid_size=grid_size, point_spacing=point_spacing)
        
        print("\n=== ç”Ÿæˆæ›²é¢ ===")
        pred = denoise_with_tree(files[0], model, betas, device='cpu', grid_size=grid_size, point_spacing=point_spacing)
        pred_gif = denoise_with_gif(files[0], model, betas, gif_path='denoise.gif', device='cpu', 
                                  grid_size=grid_size, point_spacing=point_spacing)
        print('Predicted plane points shape:', pred.shape)  # (32, 32, 3)
        print('Final points center:', pred.mean(axis=(0,1))) 
        
        # æ–°å¢ï¼šç»¼åˆéªŒè¯ç”Ÿæˆçš„æ›²é¢
        print("\n=== éªŒè¯ç”Ÿæˆçš„æ›²é¢ ===")
        comprehensive_surface_validation(files[0], pred, "trained_surface", interactive=True)

def visualize_separation_effect(tree_json: str, separation_surface: np.ndarray, interactive: bool = True):
    """
    ä¸“é—¨ç”¨äºéªŒè¯å’Œå¯è§†åŒ–åˆ†éš”æ›²é¢çš„åˆ†ç¦»æ•ˆæœ
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    # è¯»å–åŸå§‹è¡€ç®¡æ•°æ®
    with open(tree_json, 'r') as fp:
        td = json.load(fp)
    
    trunk_pts, br1_pts, br2_pts = safe_find_max_points_branches(td)
    
    # è®¡ç®—åˆ†éš”é¢å‚æ•°
    br1_center = br1_pts.mean(axis=0)
    br2_center = br2_pts.mean(axis=0)
    branch_midpoint = (br1_center + br2_center) / 2
    branch_connection = br2_center - br1_center
    
    if np.linalg.norm(branch_connection) > 1e-6:
        separation_normal = branch_connection / np.linalg.norm(branch_connection)
    else:
        separation_normal = np.array([1, 0, 0])
    
    # è®¡ç®—æ›²é¢ä¸­å¿ƒ
    surface_center = separation_surface.mean(axis=(0,1))
    
    # åˆ›å»ºå¤§å°ºå¯¸å›¾å½¢ä»¥ä¾¿è¯¦ç»†è§‚å¯Ÿ
    fig = plt.figure(figsize=(20, 8))
    
    # å­å›¾1: æ€»ä½“è§†å›¾
    ax1 = fig.add_subplot(141, projection='3d')
    
    # ç»˜åˆ¶è¡€ç®¡ç‚¹
    ax1.scatter(*trunk_pts.T, c='blue', s=3, alpha=0.8, label='ä¸»å¹²', marker='o')
    ax1.scatter(*br1_pts.T, c='green', s=5, alpha=0.9, label='åˆ†æ”¯1', marker='^')
    ax1.scatter(*br2_pts.T, c='red', s=5, alpha=0.9, label='åˆ†æ”¯2', marker='s')
    
    # ç»˜åˆ¶åˆ†æ”¯ä¸­å¿ƒ
    ax1.scatter(*br1_center, c='darkgreen', s=100, marker='*', label='åˆ†æ”¯1ä¸­å¿ƒ')
    ax1.scatter(*br2_center, c='darkred', s=100, marker='*', label='åˆ†æ”¯2ä¸­å¿ƒ')
    ax1.scatter(*branch_midpoint, c='purple', s=100, marker='D', label='åˆ†æ”¯ä¸­ç‚¹')
    
    # ç»˜åˆ¶åˆ†éš”æ›²é¢
    X, Y, Z = separation_surface[:, :, 0], separation_surface[:, :, 1], separation_surface[:, :, 2]
    ax1.plot_surface(X, Y, Z, alpha=0.4, color='orange', label='åˆ†éš”æ›²é¢')
    
    # ç»˜åˆ¶åˆ†æ”¯è¿çº¿
    ax1.plot([br1_center[0], br2_center[0]], 
             [br1_center[1], br2_center[1]], 
             [br1_center[2], br2_center[2]], 
             'purple', linewidth=3, alpha=0.8, label='åˆ†æ”¯è¿çº¿')
    
    ax1.set_title('åˆ†æ”¯åˆ†ç¦»æ€»è§†å›¾')
    ax1.legend()
    ax1.set_axis_off()
    
    # å­å›¾2: æ²¿åˆ†éš”é¢æ³•å‘é‡çš„ä¾§è§†å›¾
    ax2 = fig.add_subplot(142, projection='3d')
    
    # è®¡ç®—ç‚¹åˆ°åˆ†éš”é¢çš„è·ç¦»
    br1_distances = [np.dot(pt - surface_center, separation_normal) for pt in br1_pts]
    br2_distances = [np.dot(pt - surface_center, separation_normal) for pt in br2_pts]
    trunk_distances = [np.dot(pt - surface_center, separation_normal) for pt in trunk_pts]
    
    # æ ¹æ®åˆ°åˆ†éš”é¢çš„è·ç¦»ç»™ç‚¹ç€è‰²
    br1_colors = ['lightgreen' if d < 0 else 'darkgreen' for d in br1_distances]
    br2_colors = ['lightcoral' if d < 0 else 'darkred' for d in br2_distances]
    
    for i, (pt, color) in enumerate(zip(br1_pts, br1_colors)):
        ax2.scatter(*pt, c=color, s=8, alpha=0.8)
    for i, (pt, color) in enumerate(zip(br2_pts, br2_colors)):
        ax2.scatter(*pt, c=color, s=8, alpha=0.8)
    
    ax2.scatter(*trunk_pts.T, c='blue', s=2, alpha=0.6)
    ax2.plot_surface(X, Y, Z, alpha=0.3, color='orange')
    
    ax2.set_title('æŒ‰åˆ†éš”é¢åˆ†ä¾§ç€è‰²\n(æµ…è‰²=è´Ÿä¾§ï¼Œæ·±è‰²=æ­£ä¾§)')
    ax2.set_axis_off()
    
    # å­å›¾3: è·ç¦»åˆ†å¸ƒç»Ÿè®¡
    ax3 = fig.add_subplot(143)
    
    ax3.hist(br1_distances, bins=20, alpha=0.7, color='green', label=f'åˆ†æ”¯1 (å‡å€¼:{np.mean(br1_distances):.2f})')
    ax3.hist(br2_distances, bins=20, alpha=0.7, color='red', label=f'åˆ†æ”¯2 (å‡å€¼:{np.mean(br2_distances):.2f})')
    ax3.axvline(0, color='orange', linestyle='--', linewidth=2, label='åˆ†éš”é¢')
    ax3.set_xlabel('åˆ°åˆ†éš”é¢çš„è·ç¦»')
    ax3.set_ylabel('ç‚¹æ•°')
    ax3.set_title('åˆ†æ”¯ç‚¹åˆ°åˆ†éš”é¢è·ç¦»åˆ†å¸ƒ')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # å­å›¾4: åˆ†ç¦»æ•ˆæœé‡åŒ–
    ax4 = fig.add_subplot(144)
    
    # è®¡ç®—åˆ†ç¦»æ•ˆæœæŒ‡æ ‡
    br1_positive = sum(1 for d in br1_distances if d > 0)
    br1_negative = sum(1 for d in br1_distances if d < 0)
    br2_positive = sum(1 for d in br2_distances if d > 0)
    br2_negative = sum(1 for d in br2_distances if d < 0)
    
    # ç†æƒ³æƒ…å†µï¼šä¸¤ä¸ªåˆ†æ”¯åº”è¯¥åœ¨åˆ†éš”é¢çš„ä¸åŒä¾§
    br1_majority_side = "æ­£ä¾§" if br1_positive > br1_negative else "è´Ÿä¾§"
    br2_majority_side = "æ­£ä¾§" if br2_positive > br2_negative else "è´Ÿä¾§"
    
    separation_quality = "è‰¯å¥½" if br1_majority_side != br2_majority_side else "éœ€è¦æ”¹è¿›"
    
    # ç»˜åˆ¶åˆ†ç¦»ç»Ÿè®¡
    categories = ['åˆ†æ”¯1\næ­£ä¾§', 'åˆ†æ”¯1\nè´Ÿä¾§', 'åˆ†æ”¯2\næ­£ä¾§', 'åˆ†æ”¯2\nè´Ÿä¾§']
    values = [br1_positive, br1_negative, br2_positive, br2_negative]
    colors = ['darkgreen', 'lightgreen', 'darkred', 'lightcoral']
    
    bars = ax4.bar(categories, values, color=colors, alpha=0.8)
    ax4.set_ylabel('ç‚¹æ•°')
    ax4.set_title(f'åˆ†ç¦»æ•ˆæœç»Ÿè®¡\nåˆ†ç¦»è´¨é‡: {separation_quality}')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, value in zip(bars, values):
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, 
                str(value), ha='center', va='bottom')
    
    ax4.grid(True, alpha=0.3)
    
    # åœ¨å›¾ä¸Šæ·»åŠ åˆ†ææ–‡æœ¬
    analysis_text = f"""åˆ†ç¦»åˆ†æ:
åˆ†æ”¯1: {br1_majority_side} ({br1_positive}/{br1_positive+br1_negative})
åˆ†æ”¯2: {br2_majority_side} ({br2_positive}/{br2_positive+br2_negative})
åˆ†ç¦»è´¨é‡: {separation_quality}
"""
    
    fig.text(0.02, 0.02, analysis_text, fontsize=10, 
             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.8))
    
    # ç»Ÿä¸€è®¾ç½®3Dè§†å›¾èŒƒå›´
    all_points = np.vstack([trunk_pts, br1_pts, br2_pts])
    center = all_points.mean(axis=0)
    range_val = 30
    
    for ax in [ax1, ax2]:
        ax.set_xlim(center[0] - range_val, center[0] + range_val)
        ax.set_ylim(center[1] - range_val, center[1] + range_val)
        ax.set_zlim(center[2] - range_val, center[2] + range_val)
    
    plt.tight_layout()
    
    # æ‰“å°è¯¦ç»†åˆ†æ
    print("\n" + "="*60)
    print("åˆ†éš”æ•ˆæœè¯¦ç»†åˆ†æ")
    print("="*60)
    print(f"åˆ†æ”¯1ç‚¹æ•°: {len(br1_pts)}")
    print(f"  - åœ¨åˆ†éš”é¢æ­£ä¾§: {br1_positive} ä¸ªç‚¹")
    print(f"  - åœ¨åˆ†éš”é¢è´Ÿä¾§: {br1_negative} ä¸ªç‚¹")
    print(f"  - ä¸»è¦åˆ†å¸ƒ: {br1_majority_side}")
    print(f"  - è·ç¦»å‡å€¼: {np.mean(br1_distances):.3f}")
    
    print(f"\nåˆ†æ”¯2ç‚¹æ•°: {len(br2_pts)}")
    print(f"  - åœ¨åˆ†éš”é¢æ­£ä¾§: {br2_positive} ä¸ªç‚¹")
    print(f"  - åœ¨åˆ†éš”é¢è´Ÿä¾§: {br2_negative} ä¸ªç‚¹")
    print(f"  - ä¸»è¦åˆ†å¸ƒ: {br2_majority_side}")
    print(f"  - è·ç¦»å‡å€¼: {np.mean(br2_distances):.3f}")
    
    print(f"\nåˆ†ç¦»æ•ˆæœè¯„ä¼°:")
    print(f"  - ä¸¤åˆ†æ”¯ä¸»è¦åˆ†å¸ƒåœ¨ä¸åŒä¾§: {br1_majority_side != br2_majority_side}")
    print(f"  - åˆ†ç¦»è´¨é‡: {separation_quality}")
    
    if br1_majority_side == br2_majority_side:
        print(f"  - å»ºè®®: éœ€è¦è°ƒæ•´åˆ†éš”é¢çš„ä½ç½®æˆ–æ–¹å‘")
    else:
        print(f"  - ç»“æœ: åˆ†éš”æ›²é¢æˆåŠŸå°†ä¸¤ä¸ªåˆ†æ”¯åˆ†ç¦»")
    
    # æ˜¾ç¤ºäº¤äº’å¼ç•Œé¢ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if interactive:
        print("\næ­£åœ¨æ‰“å¼€åˆ†ç¦»æ•ˆæœéªŒè¯çš„äº¤äº’å¼ç•Œé¢...")
        plt.show()
    else:
        plt.close()

print("æµ‹è¯•merge")
print("ceshi2")

# --------- SVMæ›²é¢åˆ‡åˆ† ---------
def create_svm_separation_surface(points_group1, points_group2, grid_size=32, plane_size=10.0, kernel='rbf', C=1.0):
    """
    ä½¿ç”¨SVMåˆ›å»ºä¸€ä¸ªæ›²é¢æ¥åŒºåˆ†ä¸¤ç»„3Dç‚¹
    
    Args:
        points_group1: ç¬¬ä¸€ç»„ç‚¹ (N1, 3)
        points_group2: ç¬¬äºŒç»„ç‚¹ (N2, 3)
        grid_size: ç”Ÿæˆçš„æ›²é¢ç½‘æ ¼å¤§å°
        plane_size: æ›²é¢çš„å¤§å°èŒƒå›´
        kernel: SVMæ ¸å‡½æ•° ('linear', 'rbf', 'poly')
        C: SVMæ­£åˆ™åŒ–å‚æ•°
    
    Returns:
        separation_surface: åˆ†ç¦»æ›²é¢ (grid_size, grid_size, 3)
        svm_model: è®­ç»ƒå¥½çš„SVMæ¨¡å‹
        separation_info: åˆ†ç¦»ä¿¡æ¯å­—å…¸
    """
    from sklearn.svm import SVC
    from sklearn.preprocessing import StandardScaler
    import numpy as np
    
    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X = np.vstack([points_group1, points_group2])
    y = np.hstack([np.ones(len(points_group1)), -np.ones(len(points_group2))])
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # è®­ç»ƒSVMæ¨¡å‹
    svm_model = SVC(kernel=kernel, C=C, probability=True)
    svm_model.fit(X_scaled, y)
    
    # è®¡ç®—åˆ†ç¦»è¶…å¹³é¢çš„æ³•å‘é‡å’Œåç§»
    if kernel == 'linear':
        # çº¿æ€§æ ¸å¯ä»¥ç›´æ¥è·å–æ³•å‘é‡
        normal_vector = svm_model.coef_[0]
        bias = svm_model.intercept_[0]
    else:
        # éçº¿æ€§æ ¸éœ€è¦è¿‘ä¼¼æ³•å‘é‡
        normal_vector, bias = _approximate_svm_normal(svm_model, X_scaled, y)
    
    # è®¡ç®—ä¸¤ç»„ç‚¹çš„ä¸­å¿ƒ
    center_group1 = np.mean(points_group1, axis=0)
    center_group2 = np.mean(points_group2, axis=0)
    center = (center_group1 + center_group2) / 2
    
    # ç”Ÿæˆåˆ†ç¦»æ›²é¢
    separation_surface = _generate_separation_surface(
        center, normal_vector, bias, scaler, svm_model, 
        grid_size, plane_size, kernel
    )
    
    # è®¡ç®—åˆ†ç¦»æ•ˆæœ
    separation_info = _evaluate_separation_quality(
        points_group1, points_group2, separation_surface, svm_model, scaler
    )
    
    return separation_surface, svm_model, separation_info

def _approximate_svm_normal(svm_model, X_scaled, y):
    """
    è¿‘ä¼¼è®¡ç®—éçº¿æ€§SVMçš„æ³•å‘é‡
    """
    # ä½¿ç”¨æ”¯æŒå‘é‡æ¥è¿‘ä¼¼æ³•å‘é‡
    support_vectors = svm_model.support_vectors_
    support_vector_coefs = svm_model.dual_coef_[0]
    
    # è®¡ç®—åŠ æƒæ”¯æŒå‘é‡çš„å¹³å‡æ–¹å‘
    weighted_sv = np.sum(support_vectors * support_vector_coefs[:, np.newaxis], axis=0)
    normal_vector = weighted_sv / (np.linalg.norm(weighted_sv) + 1e-8)
    
    # è®¡ç®—åç§»
    bias = svm_model.intercept_[0]
    
    return normal_vector, bias

def _generate_separation_surface(center, normal_vector, bias, scaler, svm_model, grid_size, plane_size, kernel):
    """
    ç”Ÿæˆåˆ†ç¦»æ›²é¢
    """
    # æ„å»ºå‚ç›´äºæ³•å‘é‡çš„ä¸¤ä¸ªåŸºå‘é‡
    if abs(np.dot(normal_vector, np.array([1, 0, 0]))) < 0.9:
        base_vector = np.array([1, 0, 0])
    else:
        base_vector = np.array([0, 1, 0])
    
    u_axis = np.cross(normal_vector, base_vector)
    u_axis = u_axis / (np.linalg.norm(u_axis) + 1e-8)
    
    v_axis = np.cross(normal_vector, u_axis)
    v_axis = v_axis / (np.linalg.norm(v_axis) + 1e-8)
    
    # ç”Ÿæˆç½‘æ ¼
    g = np.linspace(-plane_size/2, plane_size/2, grid_size)
    u, v = np.meshgrid(g, g)
    
    # åˆå§‹åŒ–æ›²é¢
    surface = np.zeros((grid_size, grid_size, 3))
    
    for i in range(grid_size):
        for j in range(grid_size):
            # åŸºç¡€å¹³é¢ç‚¹
            base_point = center + u[i, j] * u_axis + v[i, j] * v_axis
            
            if kernel == 'linear':
                # çº¿æ€§æ ¸ï¼šç›´æ¥ä½¿ç”¨è¶…å¹³é¢
                # è®¡ç®—åˆ°è¶…å¹³é¢çš„è·ç¦»
                distance = np.dot(base_point, normal_vector) + bias
                # å°†ç‚¹æŠ•å½±åˆ°è¶…å¹³é¢ä¸Š
                surface[i, j] = base_point - distance * normal_vector
            else:
                # éçº¿æ€§æ ¸ï¼šä½¿ç”¨SVMå†³ç­–å‡½æ•°
                surface[i, j] = _find_decision_boundary_point(
                    base_point, normal_vector, svm_model, scaler, grid_size
                )
    
    return surface

def _find_decision_boundary_point(base_point, normal_vector, svm_model, scaler, max_iter=10):
    """
    æ‰¾åˆ°å†³ç­–è¾¹ç•Œä¸Šçš„ç‚¹
    """
    current_point = base_point.copy()
    
    for _ in range(max_iter):
        # æ ‡å‡†åŒ–å½“å‰ç‚¹
        current_point_scaled = scaler.transform(current_point.reshape(1, -1))
        
        # è®¡ç®—å†³ç­–å‡½æ•°å€¼
        decision_value = svm_model.decision_function(current_point_scaled)[0]
        
        # å¦‚æœæ¥è¿‘å†³ç­–è¾¹ç•Œï¼Œåœæ­¢è¿­ä»£
        if abs(decision_value) < 1e-3:
            break
        
        # æ²¿æ³•å‘é‡æ–¹å‘è°ƒæ•´ç‚¹
        adjustment = decision_value * normal_vector * 0.1
        current_point -= adjustment
    
    return current_point

def _evaluate_separation_quality(points_group1, points_group2, separation_surface, svm_model, scaler):
    """
    è¯„ä¼°åˆ†ç¦»è´¨é‡
    """
    # è®¡ç®—åˆ†ç¦»å‡†ç¡®ç‡
    X = np.vstack([points_group1, points_group2])
    y_true = np.hstack([np.ones(len(points_group1)), -np.ones(len(points_group2))])
    
    X_scaled = scaler.transform(X)
    y_pred = svm_model.predict(X_scaled)
    
    accuracy = np.mean(y_pred == y_true)
    
    # è®¡ç®—ä¸¤ç»„ç‚¹åˆ°æ›²é¢çš„å¹³å‡è·ç¦»
    surface_center = np.mean(separation_surface, axis=(0, 1))
    
    distances_group1 = []
    distances_group2 = []
    
    for point in points_group1:
        # æ‰¾åˆ°æ›²é¢ä¸Šæœ€è¿‘çš„ç‚¹
        distances = np.linalg.norm(separation_surface.reshape(-1, 3) - point, axis=1)
        min_distance = np.min(distances)
        distances_group1.append(min_distance)
    
    for point in points_group2:
        distances = np.linalg.norm(separation_surface.reshape(-1, 3) - point, axis=1)
        min_distance = np.min(distances)
        distances_group2.append(min_distance)
    
    avg_distance_group1 = np.mean(distances_group1)
    avg_distance_group2 = np.mean(distances_group2)
    
    # è®¡ç®—åˆ†ç¦»åº¦ï¼ˆä¸¤ç»„ç‚¹è·ç¦»çš„å·®å¼‚ï¼‰
    separation_degree = abs(avg_distance_group1 - avg_distance_group2)
    
    return {
        'accuracy': accuracy,
        'avg_distance_group1': avg_distance_group1,
        'avg_distance_group2': avg_distance_group2,
        'separation_degree': separation_degree,
        'support_vectors_count': len(svm_model.support_vectors_)
    }

def visualize_svm_separation(points_group1, points_group2, separation_surface, separation_info, 
                           save_path=None, interactive=True):
    """
    å¯è§†åŒ–SVMåˆ†ç¦»ç»“æœ
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    fig = plt.figure(figsize=(15, 10))
    fig.suptitle('SVMæ›²é¢åˆ†ç¦»å¯è§†åŒ–', fontsize=16)
    
    # ä¸»è§†å›¾ï¼šç‚¹äº‘å’Œåˆ†ç¦»æ›²é¢
    ax1 = fig.add_subplot(2, 3, 1, projection='3d')
    ax1.scatter(points_group1[:, 0], points_group1[:, 1], points_group1[:, 2], 
               c='red', s=20, alpha=0.7, label='ç»„1')
    ax1.scatter(points_group2[:, 0], points_group2[:, 1], points_group2[:, 2], 
               c='blue', s=20, alpha=0.7, label='ç»„2')
    ax1.plot_surface(separation_surface[:, :, 0], separation_surface[:, :, 1], separation_surface[:, :, 2], 
                    alpha=0.3, color='green', label='åˆ†ç¦»æ›²é¢')
    ax1.set_title('SVMåˆ†ç¦»ç»“æœ')
    ax1.set_xlabel('X'); ax1.set_ylabel('Y'); ax1.set_zlabel('Z')
    ax1.legend()
    
    # åˆ†ç¦»æ›²é¢ç»†èŠ‚
    ax2 = fig.add_subplot(2, 3, 2, projection='3d')
    ax2.plot_surface(separation_surface[:, :, 0], separation_surface[:, :, 1], separation_surface[:, :, 2], 
                    alpha=0.8, cmap='viridis')
    ax2.set_title('åˆ†ç¦»æ›²é¢')
    ax2.set_xlabel('X'); ax2.set_ylabel('Y'); ax2.set_zlabel('Z')
    
    # è·ç¦»åˆ†å¸ƒ
    ax3 = fig.add_subplot(2, 3, 3)
    distances_group1 = []
    distances_group2 = []
    
    for point in points_group1:
        distances = np.linalg.norm(separation_surface.reshape(-1, 3) - point, axis=1)
        distances_group1.append(np.min(distances))
    
    for point in points_group2:
        distances = np.linalg.norm(separation_surface.reshape(-1, 3) - point, axis=1)
        distances_group2.append(np.min(distances))
    
    ax3.hist(distances_group1, bins=20, alpha=0.7, label='ç»„1è·ç¦»', color='red')
    ax3.hist(distances_group2, bins=20, alpha=0.7, label='ç»„2è·ç¦»', color='blue')
    ax3.set_title('åˆ°åˆ†ç¦»æ›²é¢çš„è·ç¦»åˆ†å¸ƒ')
    ax3.set_xlabel('è·ç¦»'); ax3.set_ylabel('é¢‘æ¬¡')
    ax3.legend()
    
    # ç»Ÿè®¡ä¿¡æ¯
    ax4 = fig.add_subplot(2, 3, 4)
    ax4.axis('off')
    stats_text = f"""
    åˆ†ç¦»è´¨é‡ç»Ÿè®¡:
    
    å‡†ç¡®ç‡: {separation_info['accuracy']:.3f}
    ç»„1å¹³å‡è·ç¦»: {separation_info['avg_distance_group1']:.3f}
    ç»„2å¹³å‡è·ç¦»: {separation_info['avg_distance_group2']:.3f}
    åˆ†ç¦»åº¦: {separation_info['separation_degree']:.3f}
    æ”¯æŒå‘é‡æ•°é‡: {separation_info['support_vectors_count']}
    """
    ax4.text(0.1, 0.5, stats_text, fontsize=12, verticalalignment='center',
             bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))
    
    # æŠ•å½±è§†å›¾
    ax5 = fig.add_subplot(2, 3, 5)
    ax5.scatter(points_group1[:, 0], points_group1[:, 1], c='red', s=20, alpha=0.7, label='ç»„1')
    ax5.scatter(points_group2[:, 0], points_group2[:, 1], c='blue', s=20, alpha=0.7, label='ç»„2')
    ax5.set_title('XYå¹³é¢æŠ•å½±')
    ax5.set_xlabel('X'); ax5.set_ylabel('Y')
    ax5.legend()
    
    # 3DæŠ•å½±
    ax6 = fig.add_subplot(2, 3, 6, projection='3d')
    ax6.scatter(points_group1[:, 0], points_group1[:, 1], points_group1[:, 2], 
               c='red', s=20, alpha=0.7, label='ç»„1')
    ax6.scatter(points_group2[:, 0], points_group2[:, 1], points_group2[:, 2], 
               c='blue', s=20, alpha=0.7, label='ç»„2')
    ax6.set_title('3Dç‚¹äº‘åˆ†å¸ƒ')
    ax6.set_xlabel('X'); ax6.set_ylabel('Y'); ax6.set_zlabel('Z')
    ax6.legend()
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"SVMåˆ†ç¦»å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    
    if interactive:
        plt.show()
    else:
        plt.close()

# --------- å…¶ä»–åˆ†ç¦»æ–¹æ³• ---------
def create_lda_separation_surface(points_group1, points_group2, grid_size=32, plane_size=10.0):
    """
    ä½¿ç”¨çº¿æ€§åˆ¤åˆ«åˆ†æ(LDA)åˆ›å»ºåˆ†ç¦»æ›²é¢
    """
    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
    import numpy as np
    
    # å‡†å¤‡æ•°æ®
    X = np.vstack([points_group1, points_group2])
    y = np.hstack([np.ones(len(points_group1)), np.zeros(len(points_group2))])
    
    # è®­ç»ƒLDA
    lda = LinearDiscriminantAnalysis()
    lda.fit(X, y)
    
    # è·å–åˆ†ç¦»è¶…å¹³é¢
    normal_vector = lda.coef_[0]
    bias = lda.intercept_[0]
    
    # ç”Ÿæˆåˆ†ç¦»æ›²é¢
    center = (np.mean(points_group1, axis=0) + np.mean(points_group2, axis=0)) / 2
    separation_surface = _generate_lda_surface(center, normal_vector, bias, grid_size, plane_size)
    
    return separation_surface, lda

def create_kmeans_separation_surface(points_group1, points_group2, grid_size=32, plane_size=10.0):
    """
    ä½¿ç”¨K-meansèšç±»åˆ›å»ºåˆ†ç¦»æ›²é¢
    """
    from sklearn.cluster import KMeans
    import numpy as np
    
    # åˆå¹¶æ‰€æœ‰ç‚¹
    all_points = np.vstack([points_group1, points_group2])
    
    # ä½¿ç”¨K-meansèšç±»
    kmeans = KMeans(n_clusters=2, random_state=42)
    kmeans.fit(all_points)
    
    # è·å–èšç±»ä¸­å¿ƒ
    centers = kmeans.cluster_centers_
    
    # è®¡ç®—åˆ†ç¦»è¶…å¹³é¢
    normal_vector = centers[1] - centers[0]
    normal_vector = normal_vector / np.linalg.norm(normal_vector)
    bias = -np.dot(normal_vector, (centers[0] + centers[1]) / 2)
    
    # ç”Ÿæˆåˆ†ç¦»æ›²é¢
    center = (centers[0] + centers[1]) / 2
    separation_surface = _generate_lda_surface(center, normal_vector, bias, grid_size, plane_size)
    
    return separation_surface, kmeans

def _generate_lda_surface(center, normal_vector, bias, grid_size, plane_size):
    """
    ç”ŸæˆLDAåˆ†ç¦»æ›²é¢
    """
    # æ„å»ºå‚ç›´äºæ³•å‘é‡çš„ä¸¤ä¸ªåŸºå‘é‡
    if abs(np.dot(normal_vector, np.array([1, 0, 0]))) < 0.9:
        base_vector = np.array([1, 0, 0])
    else:
        base_vector = np.array([0, 1, 0])
    
    u_axis = np.cross(normal_vector, base_vector)
    u_axis = u_axis / (np.linalg.norm(u_axis) + 1e-8)
    
    v_axis = np.cross(normal_vector, u_axis)
    v_axis = v_axis / (np.linalg.norm(v_axis) + 1e-8)
    
    # ç”Ÿæˆç½‘æ ¼
    g = np.linspace(-plane_size/2, plane_size/2, grid_size)
    u, v = np.meshgrid(g, g)
    
    # ç”Ÿæˆæ›²é¢
    surface = np.zeros((grid_size, grid_size, 3))
    
    for i in range(grid_size):
        for j in range(grid_size):
            base_point = center + u[i, j] * u_axis + v[i, j] * v_axis
            distance = np.dot(base_point, normal_vector) + bias
            surface[i, j] = base_point - distance * normal_vector
    
    return surface

def demo_separation_methods():
    """
    æ¼”ç¤ºä¸åŒåˆ†ç¦»æ–¹æ³•çš„æ•ˆæœ
    """
    import numpy as np
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    print("=== æ›²é¢åˆ†ç¦»æ–¹æ³•æ¼”ç¤º ===")
    
    # ç”Ÿæˆä¸¤ç»„åˆ†ç¦»çš„ç‚¹äº‘æ•°æ®
    np.random.seed(42)
    
    # ç»„1ï¼šçƒå½¢åˆ†å¸ƒ
    n1 = 200
    r1 = 2.0
    theta1 = np.random.uniform(0, 2*np.pi, n1)
    phi1 = np.random.uniform(0, np.pi, n1)
    x1 = r1 * np.sin(phi1) * np.cos(theta1) + np.random.normal(0, 0.3, n1)
    y1 = r1 * np.sin(phi1) * np.sin(theta1) + np.random.normal(0, 0.3, n1)
    z1 = r1 * np.cos(phi1) + np.random.normal(0, 0.3, n1)
    points_group1 = np.column_stack([x1, y1, z1])
    
    # ç»„2ï¼šæ¤­çƒå½¢åˆ†å¸ƒ
    n2 = 200
    r2 = 3.0
    theta2 = np.random.uniform(0, 2*np.pi, n2)
    phi2 = np.random.uniform(0, np.pi, n2)
    x2 = r2 * np.sin(phi2) * np.cos(theta2) + np.random.normal(0, 0.3, n2)
    y2 = r2 * np.sin(phi2) * np.sin(theta2) + np.random.normal(0, 0.3, n2)
    z2 = r2 * np.cos(phi2) + np.random.normal(0, 0.3, n2)
    points_group2 = np.column_stack([x2, y2, z2])
    
    # å°†ç»„2ç§»åŠ¨åˆ°ä¸åŒä½ç½®
    points_group2 += np.array([4, 2, 1])
    
    print(f"ç”Ÿæˆæ•°æ®: ç»„1 {len(points_group1)}ä¸ªç‚¹, ç»„2 {len(points_group2)}ä¸ªç‚¹")
    
    # æµ‹è¯•ä¸åŒçš„åˆ†ç¦»æ–¹æ³•
    methods = {
        'SVM (Linear)': lambda: create_svm_separation_surface(
            points_group1, points_group2, kernel='linear', C=1.0
        ),
        'SVM (RBF)': lambda: create_svm_separation_surface(
            points_group1, points_group2, kernel='rbf', C=1.0
        ),
        'SVM (Poly)': lambda: create_svm_separation_surface(
            points_group1, points_group2, kernel='poly', C=1.0
        ),
        'LDA': lambda: create_lda_separation_surface(points_group1, points_group2),
        'K-means': lambda: create_kmeans_separation_surface(points_group1, points_group2)
    }
    
    results = {}
    
    for method_name, method_func in methods.items():
        print(f"\næ­£åœ¨æµ‹è¯• {method_name}...")
        try:
            if 'SVM' in method_name:
                surface, model, info = method_func()
                results[method_name] = {
                    'surface': surface,
                    'model': model,
                    'info': info,
                    'type': 'svm'
                }
                print(f"  - å‡†ç¡®ç‡: {info['accuracy']:.3f}")
                print(f"  - åˆ†ç¦»åº¦: {info['separation_degree']:.3f}")
                print(f"  - æ”¯æŒå‘é‡æ•°: {info['support_vectors_count']}")
            else:
                surface, model = method_func()
                results[method_name] = {
                    'surface': surface,
                    'model': model,
                    'type': 'other'
                }
                print(f"  - å®Œæˆ")
        except Exception as e:
            print(f"  - é”™è¯¯: {e}")
            results[method_name] = None
    
    # å¯è§†åŒ–æ‰€æœ‰æ–¹æ³•çš„ç»“æœ
    _visualize_all_separation_methods(points_group1, points_group2, results)
    
    return results

def _visualize_all_separation_methods(points_group1, points_group2, results):
    """
    å¯è§†åŒ–æ‰€æœ‰åˆ†ç¦»æ–¹æ³•çš„ç»“æœå¯¹æ¯”
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    # è®¡ç®—å­å›¾å¸ƒå±€
    n_methods = len([r for r in results.values() if r is not None])
    n_cols = 3
    n_rows = (n_methods + n_cols - 1) // n_cols
    
    fig = plt.figure(figsize=(15, 5 * n_rows))
    fig.suptitle('ä¸åŒåˆ†ç¦»æ–¹æ³•æ•ˆæœå¯¹æ¯”', fontsize=16)
    
    plot_idx = 1
    
    for method_name, result in results.items():
        if result is None:
            continue
            
        ax = fig.add_subplot(n_rows, n_cols, plot_idx, projection='3d')
        
        # ç»˜åˆ¶åŸå§‹ç‚¹äº‘
        ax.scatter(points_group1[:, 0], points_group1[:, 1], points_group1[:, 2], 
                  c='red', s=20, alpha=0.7, label='ç»„1')
        ax.scatter(points_group2[:, 0], points_group2[:, 1], points_group2[:, 2], 
                  c='blue', s=20, alpha=0.7, label='ç»„2')
        
        # ç»˜åˆ¶åˆ†ç¦»æ›²é¢
        surface = result['surface']
        ax.plot_surface(surface[:, :, 0], surface[:, :, 1], surface[:, :, 2], 
                       alpha=0.3, color='green')
        
        ax.set_title(f'{method_name}')
        ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if result['type'] == 'svm':
            info = result['info']
            stats_text = f"å‡†ç¡®ç‡: {info['accuracy']:.3f}\nåˆ†ç¦»åº¦: {info['separation_degree']:.3f}"
            ax.text2D(0.02, 0.98, stats_text, transform=ax.transAxes, 
                     verticalalignment='top', bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))
        
        plot_idx += 1
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_dir = "separation_visualization"
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, "separation_methods_comparison.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"\nåˆ†ç¦»æ–¹æ³•å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    
    # æ‰“å°æ€»ç»“
    print("\n=== åˆ†ç¦»æ–¹æ³•æ€»ç»“ ===")
    for method_name, result in results.items():
        if result is not None and result['type'] == 'svm':
            info = result['info']
            print(f"{method_name}:")
            print(f"  - å‡†ç¡®ç‡: {info['accuracy']:.3f}")
            print(f"  - åˆ†ç¦»åº¦: {info['separation_degree']:.3f}")
            print(f"  - æ”¯æŒå‘é‡æ•°: {info['support_vectors_count']}")
            print()

def compare_separation_methods_for_vascular_data(tree_json: str):
    """
    é’ˆå¯¹è¡€ç®¡æ•°æ®æ¯”è¾ƒä¸åŒåˆ†ç¦»æ–¹æ³•
    """
    print("=== è¡€ç®¡æ•°æ®åˆ†ç¦»æ–¹æ³•æ¯”è¾ƒ ===")
    
    # åŠ è½½è¡€ç®¡æ•°æ®
    with open(tree_json, 'r') as fp:
        tree_data = json.load(fp)
    
    # æå–ä¸»å¹²å’Œåˆ†æ”¯ç‚¹
    trunk_pts, br1_pts, br2_pts = find_max_points_branches(tree_data)
    
    print(f"ä¸»å¹²ç‚¹: {len(trunk_pts)}")
    print(f"åˆ†æ”¯1ç‚¹: {len(br1_pts)}")
    print(f"åˆ†æ”¯2ç‚¹: {len(br2_pts)}")
    
    # æ¯”è¾ƒä¸åŒæ–¹æ³•åˆ†ç¦»ä¸»å¹²å’Œåˆ†æ”¯
    methods = {
        'SVM (Linear)': lambda: create_svm_separation_surface(
            trunk_pts, np.vstack([br1_pts, br2_pts]), kernel='linear', C=1.0
        ),
        'SVM (RBF)': lambda: create_svm_separation_surface(
            trunk_pts, np.vstack([br1_pts, br2_pts]), kernel='rbf', C=1.0
        ),
        'LDA': lambda: create_lda_separation_surface(
            trunk_pts, np.vstack([br1_pts, br2_pts])
        ),
        'K-means': lambda: create_kmeans_separation_surface(
            trunk_pts, np.vstack([br1_pts, br2_pts])
        )
    }
    
    results = {}
    
    for method_name, method_func in methods.items():
        print(f"\næ­£åœ¨æµ‹è¯• {method_name}...")
        try:
            if 'SVM' in method_name:
                surface, model, info = method_func()
                results[method_name] = {
                    'surface': surface,
                    'model': model,
                    'info': info,
                    'type': 'svm'
                }
                print(f"  - å‡†ç¡®ç‡: {info['accuracy']:.3f}")
                print(f"  - åˆ†ç¦»åº¦: {info['separation_degree']:.3f}")
            else:
                surface, model = method_func()
                results[method_name] = {
                    'surface': surface,
                    'model': model,
                    'type': 'other'
                }
                print(f"  - å®Œæˆ")
        except Exception as e:
            print(f"  - é”™è¯¯: {e}")
            results[method_name] = None
    
    # å¯è§†åŒ–è¡€ç®¡åˆ†ç¦»ç»“æœ
    _visualize_vascular_separation(trunk_pts, br1_pts, br2_pts, results, tree_json)
    
    return results

def _visualize_vascular_separation(trunk_pts, br1_pts, br2_pts, results, tree_json):
    """
    å¯è§†åŒ–è¡€ç®¡åˆ†ç¦»ç»“æœ
    """
    import matplotlib.pyplot as plt
    from mpl_toolkits.mplot3d import Axes3D
    
    # è®¡ç®—å­å›¾å¸ƒå±€
    n_methods = len([r for r in results.values() if r is not None])
    n_cols = 2
    n_rows = (n_methods + n_cols - 1) // n_cols
    
    fig = plt.figure(figsize=(12, 6 * n_rows))
    fig.suptitle('è¡€ç®¡æ•°æ®åˆ†ç¦»æ–¹æ³•æ¯”è¾ƒ', fontsize=16)
    
    plot_idx = 1
    
    for method_name, result in results.items():
        if result is None:
            continue
            
        ax = fig.add_subplot(n_rows, n_cols, plot_idx, projection='3d')
        
        # ç»˜åˆ¶è¡€ç®¡ç‚¹äº‘
        ax.scatter(trunk_pts[:, 0], trunk_pts[:, 1], trunk_pts[:, 2], 
                  c='red', s=20, alpha=0.7, label='ä¸»å¹²')
        ax.scatter(br1_pts[:, 0], br1_pts[:, 1], br1_pts[:, 2], 
                  c='blue', s=20, alpha=0.7, label='åˆ†æ”¯1')
        ax.scatter(br2_pts[:, 0], br2_pts[:, 1], br2_pts[:, 2], 
                  c='green', s=20, alpha=0.7, label='åˆ†æ”¯2')
        
        # ç»˜åˆ¶åˆ†ç¦»æ›²é¢
        surface = result['surface']
        ax.plot_surface(surface[:, :, 0], surface[:, :, 1], surface[:, :, 2], 
                       alpha=0.3, color='yellow')
        
        ax.set_title(f'{method_name}')
        ax.set_xlabel('X'); ax.set_ylabel('Y'); ax.set_zlabel('Z')
        ax.legend()
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        if result['type'] == 'svm':
            info = result['info']
            stats_text = f"å‡†ç¡®ç‡: {info['accuracy']:.3f}\nåˆ†ç¦»åº¦: {info['separation_degree']:.3f}"
            ax.text2D(0.02, 0.98, stats_text, transform=ax.transAxes, 
                     verticalalignment='top', bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray"))
        
        plot_idx += 1
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    save_dir = "separation_visualization"
    os.makedirs(save_dir, exist_ok=True)
    save_path = os.path.join(save_dir, f"vascular_separation_{os.path.basename(tree_json)}.png")
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()
    
    print(f"\nè¡€ç®¡åˆ†ç¦»ç»“æœå·²ä¿å­˜: {save_path}")

# --------- Dataset ---------